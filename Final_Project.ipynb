{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HArqfUKVoK7a"
      },
      "source": [
        "# Logistic Regression for M&A Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETIheUIfoHsv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "4a44b62a-5303-451d-f9cc-bfb8f2fc0fef"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # package for plotting\n",
        "np.random.seed(1)\n",
        "'''\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Import M&A training and testing data\n",
        "file_id = '1L7sbJIMkjAoXuIZTFrbeWCuu_LV5ff0n'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "#print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
        "ma_data = downloaded.GetContentString\n",
        "\n",
        "print(ma_data)\n",
        "'''\n",
        "m_a_data = pd.read_csv('clean_m&a.csv')\n",
        "m_a_data['announced'] = pd.to_datetime(m_a_data['announced']).astype(int) / 10**9\n",
        "m_a_data['announced'] = m_a_data['announced'] / m_a_data['announced'][0]\n",
        "#print(m_a_data.dtypes)\n",
        "#print(m_a_data.head())\n",
        "m_a_data['outcomes'] = m_a_data.outcome\n",
        "m_a_data.drop('outcome',inplace=True,axis=1) #moves outcome to the last column for convenience\n",
        "m_a_data.drop('Unnamed: 0',inplace=True,axis=1)\n",
        "print(m_a_data.shape)\n",
        "\n",
        "# Select the first m inputs and labels\n",
        "n = len(m_a_data)\n",
        "m=10000\n",
        "\n",
        "# Shuffle the whole dataset\n",
        "m_a_data = m_a_data.sample(frac=1)\n",
        "#print(m_a_data.head())\n",
        "\n",
        "\n",
        "# Define the training data\n",
        "Xtrain= m_a_data.iloc[:m,:-1]\n",
        "Ytrain= m_a_data.iloc[:m,-1]\n",
        "\n",
        "X=Xtrain.iloc[:m,:].to_numpy()\n",
        "Y=Ytrain.iloc[:m].to_numpy()\n",
        "\n",
        "# Define the testing data\n",
        "Xtest=m_a_data.iloc[m:,:-1].to_numpy()\n",
        "Ytest=m_a_data.iloc[m:,-1].to_numpy()\n",
        "\n",
        "\n",
        "# A numerically stable implementation of the logistic sigmoid\n",
        "def sigmoid(z):\n",
        "    return np.where(z>0,1/(1+np.exp(-z)),np.exp(z)/(1+np.exp(z)))\n",
        "\n",
        "# Function to compute the model output, yhat\n",
        "def yhat(x,w,b):\n",
        "  return sigmoid(w@x.T+b)\n",
        "\n",
        "# # Function to compute the loss\n",
        "# # It is numerically unstable, so use the one below instead.\n",
        "# def Loss(x,y,w,b):\n",
        "#   return -y*np.log(yhat(x,w,b))-(1-y)*np.log(1-yhat(x,w,b))\n",
        "\n",
        "# A numerically stable loss function\n",
        "# This is mathematically equivalent to the one above, \n",
        "# but numerically more stable\n",
        "import scipy.special\n",
        "def Loss(X,Y,w,b):\n",
        "  Z=w@X.T+b\n",
        "  L=np.zeros_like(Y)\n",
        "  L[Y==0]=scipy.special.logsumexp([np.zeros_like(Z[Y==0]), Z[Y==0]],axis=0)\n",
        "  L[Y==1]=scipy.special.logsumexp([np.zeros_like(Z[Y==1]), -Z[Y==1]],axis=0)\n",
        "  return L\n",
        "\n",
        "# Fucntion to comptue cost, J, of an entire data set\n",
        "def Cost(X,Y,w,b):\n",
        "  return (1/np.size(X))*np.sum(Loss(X,Y,w,b))\n",
        "\n",
        "\n",
        "w=np.random.randn(31) #set the initial weights to random numbers of size 31\n",
        "b=1\n",
        "\n",
        "# Number of iterations to do grad descent\n",
        "niterations=int(2e3)\n",
        "\n",
        "\n",
        "# Learning rate\n",
        "epsilon=.00015\n",
        "\n",
        "losses=np.zeros(niterations+1)\n",
        "losses[0]=Cost(X,Y,w,b)\n",
        "for i in range(niterations):\n",
        "  dJdw=(1/m)*(X.T@(yhat(X,w,b)-Y))\n",
        "  dJdb=(1/m)*np.sum((yhat(X,w,b)-Y))\n",
        "  w=w-epsilon*dJdw\n",
        "  b=b-epsilon*dJdb\n",
        "  losses[i+1]=Cost(X,Y,w,b)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(losses)\n",
        "plt.ylabel(\"cost\")\n",
        "plt.xlabel(\"iteration number\")\n",
        "#plt.yscale(\"log\")\n",
        "\n",
        "def Classifier(x,w,b):\n",
        "  return (yhat(x,w,b)>0.5).astype(float)\n",
        "\n",
        "# Apply the classifier to the training data, X\n",
        "Guesses=Classifier(X,w,b)\n",
        "\n",
        "\n",
        "# Compute misclassification rate\n",
        "MisClassRate=np.sum(np.abs(Guesses-Y))/m\n",
        "print(\"Misclassification rate on training data =\",100*MisClassRate,\"%\")\n",
        "\n",
        "# Make some testing data compute misclass. rate\n",
        "TestingGuesses=Classifier(Xtest,w,b)\n",
        "MisClassRateTesting=np.sum(np.abs(TestingGuesses-Ytest))/(n-m)\n",
        "print(\"Misclassification rate on testing data =\",100*MisClassRateTesting,\"%\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14997, 32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: RuntimeWarning: overflow encountered in exp\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: RuntimeWarning: overflow encountered in exp\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Misclassification rate on training data = 16.09 %\n",
            "Misclassification rate on testing data = 15.869521713027817 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS_EpqKH_6mo",
        "outputId": "ac0cbe87-bc6b-4447-b4d5-18c0f7a56cfa"
      },
      "source": [
        "#for confusion matrix -- Use testing data instead.\n",
        "\n",
        "withdrawn = Ytest[Ytest==0]\n",
        "completed = Ytest[Ytest==1]\n",
        "guess_withdrawn = TestingGuesses[Ytest==0]\n",
        "guess_completed = TestingGuesses[Ytest==1]\n",
        "print('Actual:W, Predict: C',np.sum(np.abs(withdrawn-guess_withdrawn)))\n",
        "print('Actual:C, Predict: W',np.sum(np.abs(completed-guess_completed)))\n",
        "print('Actual:W, Predict: W',len(withdrawn) - np.sum(np.abs(withdrawn-guess_withdrawn)))\n",
        "print('Actual:C, Predict: C',len(completed) - np.sum(np.abs(completed-guess_completed)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual:W, Predict: C 604.0\n",
            "Actual:C, Predict: W 189.0\n",
            "Actual:W, Predict: W 39.0\n",
            "Actual:C, Predict: C 4165.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWmzYGzDZ3UN"
      },
      "source": [
        "# Deep Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNmFeWJg8SSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d4eff5d-75e5-4382-e884-11725b65655e"
      },
      "source": [
        "# MNIST with Keras\n",
        "# Make sure to set runtime to GPU!\n",
        "\n",
        "# Import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import SpatialDropout1D, Dropout\n",
        "\n",
        "np.random.seed(4)\n",
        "x_train = Xtrain.to_numpy().reshape(-1,1,31)\n",
        "y_train = Ytrain.to_numpy().reshape(-1,1)\n",
        "x_test = Xtest.reshape(-1,1,31)\n",
        "y_test = Ytest.reshape(-1,1)\n",
        "\n",
        "\n",
        "print('x_train :', np.shape(x_train))\n",
        "print('y_train :', np.shape(y_train))\n",
        "print('x_test :', np.shape(x_test))\n",
        "print('y_test :', np.shape(y_test))\n",
        "\n",
        "\n",
        "model = Sequential(name='MA_CNN')\n",
        "\n",
        "model.add(keras.Input(shape=(1,31)))\n",
        "model.add(Dense(units=30, activation='relu',kernel_regularizer=l2(.055)))\n",
        "model.add(Dense(units=50, activation='relu'))\n",
        "model.add(Dense(units=50, activation='relu'))\n",
        "model.add(Dense(units=50, activation='relu'))\n",
        "model.add(Dense(units=50, activation='relu'))\n",
        "model.add(Dense(units=50, activation='relu'))\n",
        "model.add(Dropout(.055))\n",
        "model.add(Dense(units=50, activation='relu'))\n",
        "model.add(Dense(units=30, activation='relu',kernel_regularizer=l2(.055)))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train : (10000, 1, 31)\n",
            "y_train : (10000, 1)\n",
            "x_test : (4997, 1, 31)\n",
            "y_test : (4997, 1)\n",
            "Model: \"MA_CNN\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_197 (Dense)            (None, 1, 30)             960       \n",
            "_________________________________________________________________\n",
            "dense_198 (Dense)            (None, 1, 50)             1550      \n",
            "_________________________________________________________________\n",
            "dense_199 (Dense)            (None, 1, 50)             2550      \n",
            "_________________________________________________________________\n",
            "dense_200 (Dense)            (None, 1, 50)             2550      \n",
            "_________________________________________________________________\n",
            "dense_201 (Dense)            (None, 1, 50)             2550      \n",
            "_________________________________________________________________\n",
            "dense_202 (Dense)            (None, 1, 50)             2550      \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 1, 50)             0         \n",
            "_________________________________________________________________\n",
            "dense_203 (Dense)            (None, 1, 50)             2550      \n",
            "_________________________________________________________________\n",
            "dense_204 (Dense)            (None, 1, 30)             1530      \n",
            "_________________________________________________________________\n",
            "dense_205 (Dense)            (None, 1, 1)              31        \n",
            "=================================================================\n",
            "Total params: 16,821\n",
            "Trainable params: 16,821\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qHmvvZ8ZXt7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmCnzDsorpP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7deb0d-0720-4ca3-82a5-8367715aea2f"
      },
      "source": [
        "\n",
        "hist = model.fit(x_train, y_train,\n",
        "                 epochs=700,\n",
        "                 batch_size=256,\n",
        "                 validation_data=(x_test, y_test))"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/700\n",
            "40/40 [==============================] - 2s 15ms/step - loss: 4.0711 - accuracy: 0.8600 - val_loss: 3.1549 - val_accuracy: 0.8713\n",
            "Epoch 2/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 2.8931 - accuracy: 0.8672 - val_loss: 2.3834 - val_accuracy: 0.8713\n",
            "Epoch 3/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 2.1670 - accuracy: 0.8690 - val_loss: 1.7500 - val_accuracy: 0.8683\n",
            "Epoch 4/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 1.6717 - accuracy: 0.8723 - val_loss: 1.3782 - val_accuracy: 0.8679\n",
            "Epoch 5/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 1.3347 - accuracy: 0.8667 - val_loss: 1.1860 - val_accuracy: 0.8713\n",
            "Epoch 6/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 1.1301 - accuracy: 0.8673 - val_loss: 0.9903 - val_accuracy: 0.8629\n",
            "Epoch 7/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.9717 - accuracy: 0.8634 - val_loss: 0.8626 - val_accuracy: 0.8703\n",
            "Epoch 8/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.8413 - accuracy: 0.8646 - val_loss: 0.7634 - val_accuracy: 0.8709\n",
            "Epoch 9/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.7525 - accuracy: 0.8679 - val_loss: 0.6984 - val_accuracy: 0.8711\n",
            "Epoch 10/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6873 - accuracy: 0.8723 - val_loss: 0.6560 - val_accuracy: 0.8713\n",
            "Epoch 11/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6534 - accuracy: 0.8717 - val_loss: 0.6393 - val_accuracy: 0.8679\n",
            "Epoch 12/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6398 - accuracy: 0.8715 - val_loss: 0.6048 - val_accuracy: 0.8713\n",
            "Epoch 13/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5945 - accuracy: 0.8690 - val_loss: 0.5736 - val_accuracy: 0.8711\n",
            "Epoch 14/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5689 - accuracy: 0.8741 - val_loss: 0.5664 - val_accuracy: 0.8677\n",
            "Epoch 15/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5596 - accuracy: 0.8718 - val_loss: 0.5492 - val_accuracy: 0.8697\n",
            "Epoch 16/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5622 - accuracy: 0.8675 - val_loss: 0.5335 - val_accuracy: 0.8713\n",
            "Epoch 17/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5270 - accuracy: 0.8719 - val_loss: 0.5261 - val_accuracy: 0.8707\n",
            "Epoch 18/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5508 - accuracy: 0.8666 - val_loss: 0.5048 - val_accuracy: 0.8711\n",
            "Epoch 19/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5083 - accuracy: 0.8723 - val_loss: 0.4984 - val_accuracy: 0.8713\n",
            "Epoch 20/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.8753 - val_loss: 0.4833 - val_accuracy: 0.8715\n",
            "Epoch 21/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4907 - accuracy: 0.8696 - val_loss: 0.4791 - val_accuracy: 0.8707\n",
            "Epoch 22/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4869 - accuracy: 0.8689 - val_loss: 0.4699 - val_accuracy: 0.8713\n",
            "Epoch 23/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4782 - accuracy: 0.8663 - val_loss: 0.4605 - val_accuracy: 0.8717\n",
            "Epoch 24/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4627 - accuracy: 0.8725 - val_loss: 0.4577 - val_accuracy: 0.8703\n",
            "Epoch 25/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4556 - accuracy: 0.8723 - val_loss: 0.4513 - val_accuracy: 0.8713\n",
            "Epoch 26/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4411 - accuracy: 0.8767 - val_loss: 0.4466 - val_accuracy: 0.8705\n",
            "Epoch 27/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4574 - accuracy: 0.8683 - val_loss: 0.4425 - val_accuracy: 0.8713\n",
            "Epoch 28/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.8708 - val_loss: 0.4347 - val_accuracy: 0.8713\n",
            "Epoch 29/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.8729 - val_loss: 0.4285 - val_accuracy: 0.8709\n",
            "Epoch 30/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4255 - accuracy: 0.8746 - val_loss: 0.4244 - val_accuracy: 0.8711\n",
            "Epoch 31/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8789 - val_loss: 0.4322 - val_accuracy: 0.8697\n",
            "Epoch 32/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.8703 - val_loss: 0.4199 - val_accuracy: 0.8713\n",
            "Epoch 33/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4244 - accuracy: 0.8675 - val_loss: 0.4177 - val_accuracy: 0.8693\n",
            "Epoch 34/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4107 - accuracy: 0.8739 - val_loss: 0.4096 - val_accuracy: 0.8713\n",
            "Epoch 35/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4054 - accuracy: 0.8747 - val_loss: 0.4114 - val_accuracy: 0.8707\n",
            "Epoch 36/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4023 - accuracy: 0.8772 - val_loss: 0.4043 - val_accuracy: 0.8705\n",
            "Epoch 37/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.8685 - val_loss: 0.4005 - val_accuracy: 0.8709\n",
            "Epoch 38/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8769 - val_loss: 0.4034 - val_accuracy: 0.8713\n",
            "Epoch 39/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4044 - accuracy: 0.8708 - val_loss: 0.3997 - val_accuracy: 0.8711\n",
            "Epoch 40/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8745 - val_loss: 0.4038 - val_accuracy: 0.8705\n",
            "Epoch 41/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3997 - accuracy: 0.8708 - val_loss: 0.4020 - val_accuracy: 0.8707\n",
            "Epoch 42/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8726 - val_loss: 0.4083 - val_accuracy: 0.8713\n",
            "Epoch 43/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4065 - accuracy: 0.8696 - val_loss: 0.3948 - val_accuracy: 0.8711\n",
            "Epoch 44/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8750 - val_loss: 0.3859 - val_accuracy: 0.8713\n",
            "Epoch 45/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8681 - val_loss: 0.3894 - val_accuracy: 0.8713\n",
            "Epoch 46/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3782 - accuracy: 0.8776 - val_loss: 0.3853 - val_accuracy: 0.8713\n",
            "Epoch 47/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3752 - accuracy: 0.8768 - val_loss: 0.3808 - val_accuracy: 0.8715\n",
            "Epoch 48/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.8741 - val_loss: 0.3830 - val_accuracy: 0.8709\n",
            "Epoch 49/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.8721 - val_loss: 0.3821 - val_accuracy: 0.8713\n",
            "Epoch 50/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3752 - accuracy: 0.8744 - val_loss: 0.3834 - val_accuracy: 0.8711\n",
            "Epoch 51/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3764 - accuracy: 0.8747 - val_loss: 0.3850 - val_accuracy: 0.8705\n",
            "Epoch 52/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3808 - accuracy: 0.8732 - val_loss: 0.3801 - val_accuracy: 0.8713\n",
            "Epoch 53/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8751 - val_loss: 0.3776 - val_accuracy: 0.8711\n",
            "Epoch 54/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3710 - accuracy: 0.8748 - val_loss: 0.3780 - val_accuracy: 0.8711\n",
            "Epoch 55/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.8701 - val_loss: 0.3732 - val_accuracy: 0.8715\n",
            "Epoch 56/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3750 - accuracy: 0.8700 - val_loss: 0.3690 - val_accuracy: 0.8707\n",
            "Epoch 57/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3737 - accuracy: 0.8685 - val_loss: 0.3704 - val_accuracy: 0.8713\n",
            "Epoch 58/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3755 - accuracy: 0.8671 - val_loss: 0.3689 - val_accuracy: 0.8709\n",
            "Epoch 59/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.8642 - val_loss: 0.3727 - val_accuracy: 0.8713\n",
            "Epoch 60/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.8739 - val_loss: 0.3739 - val_accuracy: 0.8711\n",
            "Epoch 61/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3761 - accuracy: 0.8734 - val_loss: 0.3779 - val_accuracy: 0.8709\n",
            "Epoch 62/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3790 - accuracy: 0.8703 - val_loss: 0.3747 - val_accuracy: 0.8713\n",
            "Epoch 63/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3697 - accuracy: 0.8737 - val_loss: 0.3709 - val_accuracy: 0.8713\n",
            "Epoch 64/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3691 - accuracy: 0.8711 - val_loss: 0.3677 - val_accuracy: 0.8713\n",
            "Epoch 65/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3708 - accuracy: 0.8725 - val_loss: 0.3677 - val_accuracy: 0.8713\n",
            "Epoch 66/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3684 - accuracy: 0.8743 - val_loss: 0.3687 - val_accuracy: 0.8713\n",
            "Epoch 67/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3665 - accuracy: 0.8726 - val_loss: 0.3686 - val_accuracy: 0.8713\n",
            "Epoch 68/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3700 - accuracy: 0.8701 - val_loss: 0.3675 - val_accuracy: 0.8713\n",
            "Epoch 69/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3670 - accuracy: 0.8706 - val_loss: 0.3664 - val_accuracy: 0.8713\n",
            "Epoch 70/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3751 - accuracy: 0.8651 - val_loss: 0.3668 - val_accuracy: 0.8713\n",
            "Epoch 71/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3537 - accuracy: 0.8780 - val_loss: 0.3664 - val_accuracy: 0.8715\n",
            "Epoch 72/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3632 - accuracy: 0.8721 - val_loss: 0.3638 - val_accuracy: 0.8717\n",
            "Epoch 73/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3666 - accuracy: 0.8712 - val_loss: 0.3753 - val_accuracy: 0.8707\n",
            "Epoch 74/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.8660 - val_loss: 0.3673 - val_accuracy: 0.8711\n",
            "Epoch 75/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3553 - accuracy: 0.8776 - val_loss: 0.3657 - val_accuracy: 0.8713\n",
            "Epoch 76/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3670 - accuracy: 0.8695 - val_loss: 0.3647 - val_accuracy: 0.8711\n",
            "Epoch 77/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3619 - accuracy: 0.8713 - val_loss: 0.3631 - val_accuracy: 0.8713\n",
            "Epoch 78/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3737 - accuracy: 0.8656 - val_loss: 0.3647 - val_accuracy: 0.8713\n",
            "Epoch 79/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3601 - accuracy: 0.8726 - val_loss: 0.3640 - val_accuracy: 0.8713\n",
            "Epoch 80/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3602 - accuracy: 0.8711 - val_loss: 0.3627 - val_accuracy: 0.8715\n",
            "Epoch 81/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3630 - accuracy: 0.8694 - val_loss: 0.3621 - val_accuracy: 0.8713\n",
            "Epoch 82/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3620 - accuracy: 0.8728 - val_loss: 0.3644 - val_accuracy: 0.8715\n",
            "Epoch 83/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3697 - accuracy: 0.8667 - val_loss: 0.3674 - val_accuracy: 0.8713\n",
            "Epoch 84/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3570 - accuracy: 0.8779 - val_loss: 0.3687 - val_accuracy: 0.8713\n",
            "Epoch 85/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3649 - accuracy: 0.8709 - val_loss: 0.3619 - val_accuracy: 0.8717\n",
            "Epoch 86/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3629 - accuracy: 0.8710 - val_loss: 0.3620 - val_accuracy: 0.8713\n",
            "Epoch 87/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3592 - accuracy: 0.8732 - val_loss: 0.3621 - val_accuracy: 0.8713\n",
            "Epoch 88/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3552 - accuracy: 0.8717 - val_loss: 0.3632 - val_accuracy: 0.8713\n",
            "Epoch 89/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3567 - accuracy: 0.8739 - val_loss: 0.3604 - val_accuracy: 0.8715\n",
            "Epoch 90/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3561 - accuracy: 0.8764 - val_loss: 0.3593 - val_accuracy: 0.8713\n",
            "Epoch 91/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3605 - accuracy: 0.8716 - val_loss: 0.3603 - val_accuracy: 0.8713\n",
            "Epoch 92/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3520 - accuracy: 0.8756 - val_loss: 0.3628 - val_accuracy: 0.8719\n",
            "Epoch 93/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3589 - accuracy: 0.8747 - val_loss: 0.3649 - val_accuracy: 0.8715\n",
            "Epoch 94/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3577 - accuracy: 0.8746 - val_loss: 0.3610 - val_accuracy: 0.8711\n",
            "Epoch 95/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3597 - accuracy: 0.8712 - val_loss: 0.3597 - val_accuracy: 0.8715\n",
            "Epoch 96/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3533 - accuracy: 0.8766 - val_loss: 0.3638 - val_accuracy: 0.8715\n",
            "Epoch 97/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3535 - accuracy: 0.8774 - val_loss: 0.3613 - val_accuracy: 0.8715\n",
            "Epoch 98/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3690 - accuracy: 0.8687 - val_loss: 0.3617 - val_accuracy: 0.8713\n",
            "Epoch 99/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3600 - accuracy: 0.8715 - val_loss: 0.3649 - val_accuracy: 0.8711\n",
            "Epoch 100/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3591 - accuracy: 0.8728 - val_loss: 0.3597 - val_accuracy: 0.8713\n",
            "Epoch 101/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3635 - accuracy: 0.8712 - val_loss: 0.3681 - val_accuracy: 0.8715\n",
            "Epoch 102/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3597 - accuracy: 0.8721 - val_loss: 0.3638 - val_accuracy: 0.8715\n",
            "Epoch 103/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3640 - accuracy: 0.8704 - val_loss: 0.3620 - val_accuracy: 0.8713\n",
            "Epoch 104/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3571 - accuracy: 0.8724 - val_loss: 0.3607 - val_accuracy: 0.8715\n",
            "Epoch 105/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3568 - accuracy: 0.8722 - val_loss: 0.3613 - val_accuracy: 0.8715\n",
            "Epoch 106/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3652 - accuracy: 0.8690 - val_loss: 0.3590 - val_accuracy: 0.8713\n",
            "Epoch 107/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3612 - accuracy: 0.8702 - val_loss: 0.3623 - val_accuracy: 0.8713\n",
            "Epoch 108/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3550 - accuracy: 0.8741 - val_loss: 0.3595 - val_accuracy: 0.8713\n",
            "Epoch 109/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3655 - accuracy: 0.8662 - val_loss: 0.3613 - val_accuracy: 0.8713\n",
            "Epoch 110/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3675 - accuracy: 0.8672 - val_loss: 0.3684 - val_accuracy: 0.8713\n",
            "Epoch 111/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3644 - accuracy: 0.8757 - val_loss: 0.3628 - val_accuracy: 0.8717\n",
            "Epoch 112/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3578 - accuracy: 0.8726 - val_loss: 0.3630 - val_accuracy: 0.8713\n",
            "Epoch 113/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3548 - accuracy: 0.8739 - val_loss: 0.3641 - val_accuracy: 0.8713\n",
            "Epoch 114/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3559 - accuracy: 0.8754 - val_loss: 0.3639 - val_accuracy: 0.8713\n",
            "Epoch 115/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3599 - accuracy: 0.8712 - val_loss: 0.3615 - val_accuracy: 0.8713\n",
            "Epoch 116/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3546 - accuracy: 0.8726 - val_loss: 0.3614 - val_accuracy: 0.8713\n",
            "Epoch 117/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3662 - accuracy: 0.8668 - val_loss: 0.3598 - val_accuracy: 0.8713\n",
            "Epoch 118/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3600 - accuracy: 0.8703 - val_loss: 0.3596 - val_accuracy: 0.8713\n",
            "Epoch 119/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3576 - accuracy: 0.8723 - val_loss: 0.3716 - val_accuracy: 0.8713\n",
            "Epoch 120/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3537 - accuracy: 0.8766 - val_loss: 0.3628 - val_accuracy: 0.8713\n",
            "Epoch 121/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3478 - accuracy: 0.8778 - val_loss: 0.3605 - val_accuracy: 0.8713\n",
            "Epoch 122/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3575 - accuracy: 0.8728 - val_loss: 0.3604 - val_accuracy: 0.8711\n",
            "Epoch 123/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3484 - accuracy: 0.8765 - val_loss: 0.3585 - val_accuracy: 0.8713\n",
            "Epoch 124/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3512 - accuracy: 0.8765 - val_loss: 0.3582 - val_accuracy: 0.8713\n",
            "Epoch 125/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3690 - accuracy: 0.8666 - val_loss: 0.3640 - val_accuracy: 0.8713\n",
            "Epoch 126/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3656 - accuracy: 0.8708 - val_loss: 0.3626 - val_accuracy: 0.8713\n",
            "Epoch 127/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3561 - accuracy: 0.8755 - val_loss: 0.3663 - val_accuracy: 0.8713\n",
            "Epoch 128/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3586 - accuracy: 0.8753 - val_loss: 0.3645 - val_accuracy: 0.8713\n",
            "Epoch 129/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3592 - accuracy: 0.8722 - val_loss: 0.3628 - val_accuracy: 0.8713\n",
            "Epoch 130/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3665 - accuracy: 0.8693 - val_loss: 0.3615 - val_accuracy: 0.8713\n",
            "Epoch 131/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3582 - accuracy: 0.8728 - val_loss: 0.3630 - val_accuracy: 0.8713\n",
            "Epoch 132/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3583 - accuracy: 0.8711 - val_loss: 0.3606 - val_accuracy: 0.8711\n",
            "Epoch 133/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3549 - accuracy: 0.8719 - val_loss: 0.3600 - val_accuracy: 0.8713\n",
            "Epoch 134/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3618 - accuracy: 0.8681 - val_loss: 0.3619 - val_accuracy: 0.8713\n",
            "Epoch 135/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3570 - accuracy: 0.8711 - val_loss: 0.3601 - val_accuracy: 0.8713\n",
            "Epoch 136/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3537 - accuracy: 0.8728 - val_loss: 0.3586 - val_accuracy: 0.8713\n",
            "Epoch 137/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3610 - accuracy: 0.8676 - val_loss: 0.3581 - val_accuracy: 0.8713\n",
            "Epoch 138/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3530 - accuracy: 0.8749 - val_loss: 0.3614 - val_accuracy: 0.8713\n",
            "Epoch 139/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3524 - accuracy: 0.8739 - val_loss: 0.3592 - val_accuracy: 0.8713\n",
            "Epoch 140/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3553 - accuracy: 0.8736 - val_loss: 0.3619 - val_accuracy: 0.8713\n",
            "Epoch 141/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3647 - accuracy: 0.8676 - val_loss: 0.3606 - val_accuracy: 0.8713\n",
            "Epoch 142/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3535 - accuracy: 0.8700 - val_loss: 0.3579 - val_accuracy: 0.8713\n",
            "Epoch 143/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3459 - accuracy: 0.8773 - val_loss: 0.3588 - val_accuracy: 0.8713\n",
            "Epoch 144/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3538 - accuracy: 0.8720 - val_loss: 0.3606 - val_accuracy: 0.8713\n",
            "Epoch 145/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3604 - accuracy: 0.8694 - val_loss: 0.3611 - val_accuracy: 0.8713\n",
            "Epoch 146/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3432 - accuracy: 0.8784 - val_loss: 0.3607 - val_accuracy: 0.8713\n",
            "Epoch 147/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3606 - accuracy: 0.8678 - val_loss: 0.3600 - val_accuracy: 0.8713\n",
            "Epoch 148/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3550 - accuracy: 0.8743 - val_loss: 0.3676 - val_accuracy: 0.8713\n",
            "Epoch 149/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3638 - accuracy: 0.8727 - val_loss: 0.3621 - val_accuracy: 0.8713\n",
            "Epoch 150/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3581 - accuracy: 0.8716 - val_loss: 0.3645 - val_accuracy: 0.8713\n",
            "Epoch 151/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3516 - accuracy: 0.8765 - val_loss: 0.3644 - val_accuracy: 0.8713\n",
            "Epoch 152/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3556 - accuracy: 0.8737 - val_loss: 0.3607 - val_accuracy: 0.8713\n",
            "Epoch 153/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3584 - accuracy: 0.8698 - val_loss: 0.3594 - val_accuracy: 0.8713\n",
            "Epoch 154/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3567 - accuracy: 0.8719 - val_loss: 0.3581 - val_accuracy: 0.8713\n",
            "Epoch 155/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3721 - accuracy: 0.8677 - val_loss: 0.3590 - val_accuracy: 0.8713\n",
            "Epoch 156/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3577 - accuracy: 0.8714 - val_loss: 0.3578 - val_accuracy: 0.8713\n",
            "Epoch 157/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3463 - accuracy: 0.8754 - val_loss: 0.3593 - val_accuracy: 0.8713\n",
            "Epoch 158/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3521 - accuracy: 0.8730 - val_loss: 0.3586 - val_accuracy: 0.8713\n",
            "Epoch 159/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3561 - accuracy: 0.8716 - val_loss: 0.3618 - val_accuracy: 0.8713\n",
            "Epoch 160/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3489 - accuracy: 0.8774 - val_loss: 0.3607 - val_accuracy: 0.8713\n",
            "Epoch 161/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3637 - accuracy: 0.8692 - val_loss: 0.3582 - val_accuracy: 0.8713\n",
            "Epoch 162/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3577 - accuracy: 0.8694 - val_loss: 0.3605 - val_accuracy: 0.8713\n",
            "Epoch 163/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3607 - accuracy: 0.8693 - val_loss: 0.3601 - val_accuracy: 0.8713\n",
            "Epoch 164/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3611 - accuracy: 0.8692 - val_loss: 0.3633 - val_accuracy: 0.8713\n",
            "Epoch 165/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8681 - val_loss: 0.3664 - val_accuracy: 0.8713\n",
            "Epoch 166/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3575 - accuracy: 0.8729 - val_loss: 0.3634 - val_accuracy: 0.8713\n",
            "Epoch 167/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3533 - accuracy: 0.8752 - val_loss: 0.3615 - val_accuracy: 0.8713\n",
            "Epoch 168/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3593 - accuracy: 0.8717 - val_loss: 0.3647 - val_accuracy: 0.8713\n",
            "Epoch 169/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3555 - accuracy: 0.8753 - val_loss: 0.3595 - val_accuracy: 0.8713\n",
            "Epoch 170/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3533 - accuracy: 0.8722 - val_loss: 0.3609 - val_accuracy: 0.8713\n",
            "Epoch 171/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3551 - accuracy: 0.8724 - val_loss: 0.3583 - val_accuracy: 0.8713\n",
            "Epoch 172/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3488 - accuracy: 0.8750 - val_loss: 0.3602 - val_accuracy: 0.8713\n",
            "Epoch 173/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3560 - accuracy: 0.8699 - val_loss: 0.3572 - val_accuracy: 0.8713\n",
            "Epoch 174/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3444 - accuracy: 0.8784 - val_loss: 0.3623 - val_accuracy: 0.8713\n",
            "Epoch 175/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3654 - accuracy: 0.8658 - val_loss: 0.3605 - val_accuracy: 0.8713\n",
            "Epoch 176/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3533 - accuracy: 0.8742 - val_loss: 0.3584 - val_accuracy: 0.8713\n",
            "Epoch 177/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3515 - accuracy: 0.8741 - val_loss: 0.3606 - val_accuracy: 0.8713\n",
            "Epoch 178/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3570 - accuracy: 0.8694 - val_loss: 0.3592 - val_accuracy: 0.8713\n",
            "Epoch 179/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3573 - accuracy: 0.8672 - val_loss: 0.3590 - val_accuracy: 0.8713\n",
            "Epoch 180/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3589 - accuracy: 0.8700 - val_loss: 0.3584 - val_accuracy: 0.8713\n",
            "Epoch 181/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3564 - accuracy: 0.8705 - val_loss: 0.3593 - val_accuracy: 0.8713\n",
            "Epoch 182/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3635 - accuracy: 0.8668 - val_loss: 0.3594 - val_accuracy: 0.8713\n",
            "Epoch 183/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3607 - accuracy: 0.8715 - val_loss: 0.3579 - val_accuracy: 0.8713\n",
            "Epoch 184/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3554 - accuracy: 0.8718 - val_loss: 0.3579 - val_accuracy: 0.8713\n",
            "Epoch 185/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3499 - accuracy: 0.8747 - val_loss: 0.3585 - val_accuracy: 0.8713\n",
            "Epoch 186/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3530 - accuracy: 0.8726 - val_loss: 0.3599 - val_accuracy: 0.8713\n",
            "Epoch 187/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3501 - accuracy: 0.8757 - val_loss: 0.3632 - val_accuracy: 0.8713\n",
            "Epoch 188/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3518 - accuracy: 0.8747 - val_loss: 0.3604 - val_accuracy: 0.8713\n",
            "Epoch 189/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3488 - accuracy: 0.8747 - val_loss: 0.3631 - val_accuracy: 0.8713\n",
            "Epoch 190/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3707 - accuracy: 0.8665 - val_loss: 0.3640 - val_accuracy: 0.8713\n",
            "Epoch 191/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3620 - accuracy: 0.8710 - val_loss: 0.3623 - val_accuracy: 0.8713\n",
            "Epoch 192/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3559 - accuracy: 0.8732 - val_loss: 0.3589 - val_accuracy: 0.8713\n",
            "Epoch 193/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3592 - accuracy: 0.8692 - val_loss: 0.3589 - val_accuracy: 0.8713\n",
            "Epoch 194/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3635 - accuracy: 0.8716 - val_loss: 0.3565 - val_accuracy: 0.8713\n",
            "Epoch 195/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3634 - accuracy: 0.8688 - val_loss: 0.3647 - val_accuracy: 0.8713\n",
            "Epoch 196/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3597 - accuracy: 0.8707 - val_loss: 0.3621 - val_accuracy: 0.8713\n",
            "Epoch 197/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3601 - accuracy: 0.8684 - val_loss: 0.3621 - val_accuracy: 0.8713\n",
            "Epoch 198/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3680 - accuracy: 0.8659 - val_loss: 0.3598 - val_accuracy: 0.8713\n",
            "Epoch 199/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3512 - accuracy: 0.8727 - val_loss: 0.3610 - val_accuracy: 0.8713\n",
            "Epoch 200/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3604 - accuracy: 0.8703 - val_loss: 0.3622 - val_accuracy: 0.8713\n",
            "Epoch 201/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3557 - accuracy: 0.8722 - val_loss: 0.3595 - val_accuracy: 0.8713\n",
            "Epoch 202/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3527 - accuracy: 0.8727 - val_loss: 0.3600 - val_accuracy: 0.8713\n",
            "Epoch 203/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3504 - accuracy: 0.8747 - val_loss: 0.3606 - val_accuracy: 0.8713\n",
            "Epoch 204/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3509 - accuracy: 0.8765 - val_loss: 0.3598 - val_accuracy: 0.8713\n",
            "Epoch 205/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3517 - accuracy: 0.8738 - val_loss: 0.3596 - val_accuracy: 0.8713\n",
            "Epoch 206/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3497 - accuracy: 0.8751 - val_loss: 0.3604 - val_accuracy: 0.8713\n",
            "Epoch 207/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3519 - accuracy: 0.8718 - val_loss: 0.3611 - val_accuracy: 0.8713\n",
            "Epoch 208/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3703 - accuracy: 0.8645 - val_loss: 0.3619 - val_accuracy: 0.8713\n",
            "Epoch 209/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3596 - accuracy: 0.8709 - val_loss: 0.3626 - val_accuracy: 0.8713\n",
            "Epoch 210/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3525 - accuracy: 0.8718 - val_loss: 0.3585 - val_accuracy: 0.8713\n",
            "Epoch 211/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3582 - accuracy: 0.8697 - val_loss: 0.3625 - val_accuracy: 0.8713\n",
            "Epoch 212/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3667 - accuracy: 0.8705 - val_loss: 0.3624 - val_accuracy: 0.8713\n",
            "Epoch 213/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3566 - accuracy: 0.8720 - val_loss: 0.3627 - val_accuracy: 0.8713\n",
            "Epoch 214/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3538 - accuracy: 0.8734 - val_loss: 0.3637 - val_accuracy: 0.8713\n",
            "Epoch 215/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3641 - accuracy: 0.8681 - val_loss: 0.3589 - val_accuracy: 0.8713\n",
            "Epoch 216/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3498 - accuracy: 0.8715 - val_loss: 0.3601 - val_accuracy: 0.8713\n",
            "Epoch 217/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3535 - accuracy: 0.8738 - val_loss: 0.3599 - val_accuracy: 0.8713\n",
            "Epoch 218/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3523 - accuracy: 0.8718 - val_loss: 0.3608 - val_accuracy: 0.8713\n",
            "Epoch 219/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.8778 - val_loss: 0.3586 - val_accuracy: 0.8713\n",
            "Epoch 220/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3596 - accuracy: 0.8684 - val_loss: 0.3587 - val_accuracy: 0.8713\n",
            "Epoch 221/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3473 - accuracy: 0.8755 - val_loss: 0.3612 - val_accuracy: 0.8713\n",
            "Epoch 222/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3462 - accuracy: 0.8759 - val_loss: 0.3576 - val_accuracy: 0.8713\n",
            "Epoch 223/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3456 - accuracy: 0.8756 - val_loss: 0.3597 - val_accuracy: 0.8713\n",
            "Epoch 224/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3525 - accuracy: 0.8690 - val_loss: 0.3583 - val_accuracy: 0.8713\n",
            "Epoch 225/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3411 - accuracy: 0.8767 - val_loss: 0.3625 - val_accuracy: 0.8713\n",
            "Epoch 226/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3545 - accuracy: 0.8725 - val_loss: 0.3575 - val_accuracy: 0.8713\n",
            "Epoch 227/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3503 - accuracy: 0.8737 - val_loss: 0.3597 - val_accuracy: 0.8713\n",
            "Epoch 228/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3579 - accuracy: 0.8686 - val_loss: 0.3569 - val_accuracy: 0.8713\n",
            "Epoch 229/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3442 - accuracy: 0.8739 - val_loss: 0.3606 - val_accuracy: 0.8713\n",
            "Epoch 230/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3536 - accuracy: 0.8709 - val_loss: 0.3601 - val_accuracy: 0.8713\n",
            "Epoch 231/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3499 - accuracy: 0.8709 - val_loss: 0.3609 - val_accuracy: 0.8713\n",
            "Epoch 232/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3606 - accuracy: 0.8706 - val_loss: 0.3586 - val_accuracy: 0.8713\n",
            "Epoch 233/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3452 - accuracy: 0.8762 - val_loss: 0.3574 - val_accuracy: 0.8713\n",
            "Epoch 234/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3414 - accuracy: 0.8782 - val_loss: 0.3587 - val_accuracy: 0.8713\n",
            "Epoch 235/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3489 - accuracy: 0.8737 - val_loss: 0.3672 - val_accuracy: 0.8713\n",
            "Epoch 236/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3649 - accuracy: 0.8680 - val_loss: 0.3620 - val_accuracy: 0.8713\n",
            "Epoch 237/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3551 - accuracy: 0.8752 - val_loss: 0.3671 - val_accuracy: 0.8713\n",
            "Epoch 238/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3558 - accuracy: 0.8741 - val_loss: 0.3606 - val_accuracy: 0.8713\n",
            "Epoch 239/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3585 - accuracy: 0.8717 - val_loss: 0.3593 - val_accuracy: 0.8713\n",
            "Epoch 240/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3599 - accuracy: 0.8720 - val_loss: 0.3591 - val_accuracy: 0.8713\n",
            "Epoch 241/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3593 - accuracy: 0.8706 - val_loss: 0.3592 - val_accuracy: 0.8713\n",
            "Epoch 242/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3477 - accuracy: 0.8756 - val_loss: 0.3610 - val_accuracy: 0.8713\n",
            "Epoch 243/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3566 - accuracy: 0.8716 - val_loss: 0.3580 - val_accuracy: 0.8713\n",
            "Epoch 244/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3525 - accuracy: 0.8726 - val_loss: 0.3599 - val_accuracy: 0.8713\n",
            "Epoch 245/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3505 - accuracy: 0.8744 - val_loss: 0.3617 - val_accuracy: 0.8713\n",
            "Epoch 246/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3500 - accuracy: 0.8755 - val_loss: 0.3615 - val_accuracy: 0.8713\n",
            "Epoch 247/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3560 - accuracy: 0.8683 - val_loss: 0.3584 - val_accuracy: 0.8713\n",
            "Epoch 248/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3517 - accuracy: 0.8727 - val_loss: 0.3582 - val_accuracy: 0.8713\n",
            "Epoch 249/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3477 - accuracy: 0.8728 - val_loss: 0.3589 - val_accuracy: 0.8713\n",
            "Epoch 250/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3516 - accuracy: 0.8708 - val_loss: 0.3575 - val_accuracy: 0.8713\n",
            "Epoch 251/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3421 - accuracy: 0.8735 - val_loss: 0.3593 - val_accuracy: 0.8713\n",
            "Epoch 252/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3628 - accuracy: 0.8712 - val_loss: 0.3586 - val_accuracy: 0.8713\n",
            "Epoch 253/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3565 - accuracy: 0.8736 - val_loss: 0.3573 - val_accuracy: 0.8713\n",
            "Epoch 254/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3592 - accuracy: 0.8695 - val_loss: 0.3591 - val_accuracy: 0.8713\n",
            "Epoch 255/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3619 - accuracy: 0.8672 - val_loss: 0.3593 - val_accuracy: 0.8713\n",
            "Epoch 256/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3609 - accuracy: 0.8748 - val_loss: 0.3700 - val_accuracy: 0.8713\n",
            "Epoch 257/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3628 - accuracy: 0.8726 - val_loss: 0.3645 - val_accuracy: 0.8713\n",
            "Epoch 258/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3525 - accuracy: 0.8755 - val_loss: 0.3631 - val_accuracy: 0.8713\n",
            "Epoch 259/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3481 - accuracy: 0.8770 - val_loss: 0.3629 - val_accuracy: 0.8713\n",
            "Epoch 260/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3487 - accuracy: 0.8735 - val_loss: 0.3618 - val_accuracy: 0.8713\n",
            "Epoch 261/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3591 - accuracy: 0.8682 - val_loss: 0.3605 - val_accuracy: 0.8713\n",
            "Epoch 262/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3486 - accuracy: 0.8740 - val_loss: 0.3616 - val_accuracy: 0.8713\n",
            "Epoch 263/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3495 - accuracy: 0.8751 - val_loss: 0.3604 - val_accuracy: 0.8713\n",
            "Epoch 264/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3492 - accuracy: 0.8735 - val_loss: 0.3646 - val_accuracy: 0.8713\n",
            "Epoch 265/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3605 - accuracy: 0.8707 - val_loss: 0.3613 - val_accuracy: 0.8713\n",
            "Epoch 266/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3576 - accuracy: 0.8707 - val_loss: 0.3593 - val_accuracy: 0.8713\n",
            "Epoch 267/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3417 - accuracy: 0.8738 - val_loss: 0.3610 - val_accuracy: 0.8713\n",
            "Epoch 268/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3472 - accuracy: 0.8747 - val_loss: 0.3647 - val_accuracy: 0.8713\n",
            "Epoch 269/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3472 - accuracy: 0.8751 - val_loss: 0.3632 - val_accuracy: 0.8713\n",
            "Epoch 270/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3436 - accuracy: 0.8753 - val_loss: 0.3620 - val_accuracy: 0.8713\n",
            "Epoch 271/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3425 - accuracy: 0.8751 - val_loss: 0.3615 - val_accuracy: 0.8713\n",
            "Epoch 272/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3503 - accuracy: 0.8663 - val_loss: 0.3614 - val_accuracy: 0.8713\n",
            "Epoch 273/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3471 - accuracy: 0.8705 - val_loss: 0.3616 - val_accuracy: 0.8713\n",
            "Epoch 274/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.8743 - val_loss: 0.3602 - val_accuracy: 0.8713\n",
            "Epoch 275/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3444 - accuracy: 0.8727 - val_loss: 0.3651 - val_accuracy: 0.8713\n",
            "Epoch 276/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3554 - accuracy: 0.8755 - val_loss: 0.3586 - val_accuracy: 0.8713\n",
            "Epoch 277/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3527 - accuracy: 0.8707 - val_loss: 0.3592 - val_accuracy: 0.8713\n",
            "Epoch 278/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3468 - accuracy: 0.8726 - val_loss: 0.3578 - val_accuracy: 0.8713\n",
            "Epoch 279/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3517 - accuracy: 0.8697 - val_loss: 0.3591 - val_accuracy: 0.8713\n",
            "Epoch 280/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3504 - accuracy: 0.8690 - val_loss: 0.3592 - val_accuracy: 0.8713\n",
            "Epoch 281/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3545 - accuracy: 0.8693 - val_loss: 0.3580 - val_accuracy: 0.8713\n",
            "Epoch 282/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3364 - accuracy: 0.8735 - val_loss: 0.3615 - val_accuracy: 0.8713\n",
            "Epoch 283/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3474 - accuracy: 0.8688 - val_loss: 0.3656 - val_accuracy: 0.8713\n",
            "Epoch 284/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3457 - accuracy: 0.8727 - val_loss: 0.3626 - val_accuracy: 0.8713\n",
            "Epoch 285/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3446 - accuracy: 0.8706 - val_loss: 0.3601 - val_accuracy: 0.8713\n",
            "Epoch 286/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3610 - accuracy: 0.8662 - val_loss: 0.3640 - val_accuracy: 0.8713\n",
            "Epoch 287/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3512 - accuracy: 0.8737 - val_loss: 0.3642 - val_accuracy: 0.8713\n",
            "Epoch 288/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3499 - accuracy: 0.8722 - val_loss: 0.3611 - val_accuracy: 0.8713\n",
            "Epoch 289/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3460 - accuracy: 0.8697 - val_loss: 0.3612 - val_accuracy: 0.8713\n",
            "Epoch 290/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3388 - accuracy: 0.8760 - val_loss: 0.3605 - val_accuracy: 0.8713\n",
            "Epoch 291/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3391 - accuracy: 0.8736 - val_loss: 0.3652 - val_accuracy: 0.8713\n",
            "Epoch 292/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3364 - accuracy: 0.8773 - val_loss: 0.3634 - val_accuracy: 0.8713\n",
            "Epoch 293/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3492 - accuracy: 0.8709 - val_loss: 0.3651 - val_accuracy: 0.8713\n",
            "Epoch 294/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3413 - accuracy: 0.8746 - val_loss: 0.3635 - val_accuracy: 0.8713\n",
            "Epoch 295/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3435 - accuracy: 0.8751 - val_loss: 0.3605 - val_accuracy: 0.8713\n",
            "Epoch 296/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3454 - accuracy: 0.8730 - val_loss: 0.3658 - val_accuracy: 0.8713\n",
            "Epoch 297/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3434 - accuracy: 0.8706 - val_loss: 0.3596 - val_accuracy: 0.8713\n",
            "Epoch 298/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3435 - accuracy: 0.8757 - val_loss: 0.3578 - val_accuracy: 0.8713\n",
            "Epoch 299/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3454 - accuracy: 0.8706 - val_loss: 0.3631 - val_accuracy: 0.8713\n",
            "Epoch 300/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3403 - accuracy: 0.8755 - val_loss: 0.3604 - val_accuracy: 0.8713\n",
            "Epoch 301/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3493 - accuracy: 0.8693 - val_loss: 0.3609 - val_accuracy: 0.8713\n",
            "Epoch 302/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3421 - accuracy: 0.8702 - val_loss: 0.3624 - val_accuracy: 0.8713\n",
            "Epoch 303/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3428 - accuracy: 0.8710 - val_loss: 0.3627 - val_accuracy: 0.8713\n",
            "Epoch 304/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3368 - accuracy: 0.8740 - val_loss: 0.3645 - val_accuracy: 0.8713\n",
            "Epoch 305/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3390 - accuracy: 0.8743 - val_loss: 0.3668 - val_accuracy: 0.8713\n",
            "Epoch 306/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3454 - accuracy: 0.8724 - val_loss: 0.3714 - val_accuracy: 0.8713\n",
            "Epoch 307/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3490 - accuracy: 0.8691 - val_loss: 0.3680 - val_accuracy: 0.8713\n",
            "Epoch 308/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3515 - accuracy: 0.8741 - val_loss: 0.3686 - val_accuracy: 0.8713\n",
            "Epoch 309/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3417 - accuracy: 0.8779 - val_loss: 0.3626 - val_accuracy: 0.8713\n",
            "Epoch 310/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3499 - accuracy: 0.8700 - val_loss: 0.3619 - val_accuracy: 0.8713\n",
            "Epoch 311/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3426 - accuracy: 0.8746 - val_loss: 0.3624 - val_accuracy: 0.8713\n",
            "Epoch 312/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3386 - accuracy: 0.8744 - val_loss: 0.3637 - val_accuracy: 0.8713\n",
            "Epoch 313/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3487 - accuracy: 0.8675 - val_loss: 0.3653 - val_accuracy: 0.8713\n",
            "Epoch 314/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3470 - accuracy: 0.8716 - val_loss: 0.3667 - val_accuracy: 0.8713\n",
            "Epoch 315/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3397 - accuracy: 0.8708 - val_loss: 0.3678 - val_accuracy: 0.8713\n",
            "Epoch 316/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3316 - accuracy: 0.8755 - val_loss: 0.3673 - val_accuracy: 0.8713\n",
            "Epoch 317/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3473 - accuracy: 0.8701 - val_loss: 0.3713 - val_accuracy: 0.8713\n",
            "Epoch 318/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3443 - accuracy: 0.8732 - val_loss: 0.3665 - val_accuracy: 0.8713\n",
            "Epoch 319/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3444 - accuracy: 0.8708 - val_loss: 0.3731 - val_accuracy: 0.8713\n",
            "Epoch 320/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3579 - accuracy: 0.8680 - val_loss: 0.3683 - val_accuracy: 0.8713\n",
            "Epoch 321/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3379 - accuracy: 0.8759 - val_loss: 0.3751 - val_accuracy: 0.8713\n",
            "Epoch 322/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3488 - accuracy: 0.8726 - val_loss: 0.3669 - val_accuracy: 0.8713\n",
            "Epoch 323/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3509 - accuracy: 0.8721 - val_loss: 0.3620 - val_accuracy: 0.8713\n",
            "Epoch 324/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3434 - accuracy: 0.8722 - val_loss: 0.3743 - val_accuracy: 0.8713\n",
            "Epoch 325/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3392 - accuracy: 0.8734 - val_loss: 0.3684 - val_accuracy: 0.8713\n",
            "Epoch 326/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3413 - accuracy: 0.8722 - val_loss: 0.3636 - val_accuracy: 0.8713\n",
            "Epoch 327/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3389 - accuracy: 0.8737 - val_loss: 0.3693 - val_accuracy: 0.8713\n",
            "Epoch 328/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3499 - accuracy: 0.8675 - val_loss: 0.3742 - val_accuracy: 0.8713\n",
            "Epoch 329/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3626 - accuracy: 0.8689 - val_loss: 0.3633 - val_accuracy: 0.8713\n",
            "Epoch 330/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3448 - accuracy: 0.8716 - val_loss: 0.3650 - val_accuracy: 0.8713\n",
            "Epoch 331/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3310 - accuracy: 0.8810 - val_loss: 0.3669 - val_accuracy: 0.8713\n",
            "Epoch 332/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3455 - accuracy: 0.8730 - val_loss: 0.3683 - val_accuracy: 0.8713\n",
            "Epoch 333/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3480 - accuracy: 0.8680 - val_loss: 0.3703 - val_accuracy: 0.8713\n",
            "Epoch 334/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3459 - accuracy: 0.8712 - val_loss: 0.3751 - val_accuracy: 0.8713\n",
            "Epoch 335/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3524 - accuracy: 0.8678 - val_loss: 0.3687 - val_accuracy: 0.8713\n",
            "Epoch 336/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3516 - accuracy: 0.8668 - val_loss: 0.3751 - val_accuracy: 0.8713\n",
            "Epoch 337/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3444 - accuracy: 0.8728 - val_loss: 0.3689 - val_accuracy: 0.8713\n",
            "Epoch 338/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3412 - accuracy: 0.8725 - val_loss: 0.3703 - val_accuracy: 0.8713\n",
            "Epoch 339/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3399 - accuracy: 0.8736 - val_loss: 0.3721 - val_accuracy: 0.8713\n",
            "Epoch 340/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3412 - accuracy: 0.8729 - val_loss: 0.3671 - val_accuracy: 0.8713\n",
            "Epoch 341/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3325 - accuracy: 0.8738 - val_loss: 0.3836 - val_accuracy: 0.8713\n",
            "Epoch 342/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3306 - accuracy: 0.8763 - val_loss: 0.3715 - val_accuracy: 0.8713\n",
            "Epoch 343/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3477 - accuracy: 0.8703 - val_loss: 0.3755 - val_accuracy: 0.8713\n",
            "Epoch 344/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3500 - accuracy: 0.8717 - val_loss: 0.3691 - val_accuracy: 0.8713\n",
            "Epoch 345/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3274 - accuracy: 0.8775 - val_loss: 0.3705 - val_accuracy: 0.8713\n",
            "Epoch 346/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3383 - accuracy: 0.8742 - val_loss: 0.3804 - val_accuracy: 0.8713\n",
            "Epoch 347/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3463 - accuracy: 0.8681 - val_loss: 0.3737 - val_accuracy: 0.8713\n",
            "Epoch 348/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3309 - accuracy: 0.8769 - val_loss: 0.3701 - val_accuracy: 0.8713\n",
            "Epoch 349/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3363 - accuracy: 0.8756 - val_loss: 0.3791 - val_accuracy: 0.8713\n",
            "Epoch 350/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3378 - accuracy: 0.8714 - val_loss: 0.3710 - val_accuracy: 0.8713\n",
            "Epoch 351/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3347 - accuracy: 0.8731 - val_loss: 0.3703 - val_accuracy: 0.8713\n",
            "Epoch 352/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3254 - accuracy: 0.8765 - val_loss: 0.3843 - val_accuracy: 0.8713\n",
            "Epoch 353/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3360 - accuracy: 0.8744 - val_loss: 0.3687 - val_accuracy: 0.8713\n",
            "Epoch 354/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3459 - accuracy: 0.8692 - val_loss: 0.3710 - val_accuracy: 0.8713\n",
            "Epoch 355/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3389 - accuracy: 0.8699 - val_loss: 0.3799 - val_accuracy: 0.8713\n",
            "Epoch 356/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3468 - accuracy: 0.8689 - val_loss: 0.3708 - val_accuracy: 0.8713\n",
            "Epoch 357/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3354 - accuracy: 0.8750 - val_loss: 0.3738 - val_accuracy: 0.8713\n",
            "Epoch 358/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3323 - accuracy: 0.8746 - val_loss: 0.3734 - val_accuracy: 0.8713\n",
            "Epoch 359/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3346 - accuracy: 0.8729 - val_loss: 0.3695 - val_accuracy: 0.8713\n",
            "Epoch 360/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3326 - accuracy: 0.8733 - val_loss: 0.3676 - val_accuracy: 0.8713\n",
            "Epoch 361/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3317 - accuracy: 0.8706 - val_loss: 0.3768 - val_accuracy: 0.8713\n",
            "Epoch 362/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3291 - accuracy: 0.8742 - val_loss: 0.3791 - val_accuracy: 0.8711\n",
            "Epoch 363/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3280 - accuracy: 0.8737 - val_loss: 0.3836 - val_accuracy: 0.8713\n",
            "Epoch 364/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.8736 - val_loss: 0.3764 - val_accuracy: 0.8713\n",
            "Epoch 365/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3409 - accuracy: 0.8704 - val_loss: 0.3788 - val_accuracy: 0.8713\n",
            "Epoch 366/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3313 - accuracy: 0.8739 - val_loss: 0.3831 - val_accuracy: 0.8713\n",
            "Epoch 367/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3264 - accuracy: 0.8757 - val_loss: 0.3759 - val_accuracy: 0.8713\n",
            "Epoch 368/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3271 - accuracy: 0.8759 - val_loss: 0.3770 - val_accuracy: 0.8713\n",
            "Epoch 369/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3284 - accuracy: 0.8746 - val_loss: 0.3753 - val_accuracy: 0.8713\n",
            "Epoch 370/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3345 - accuracy: 0.8676 - val_loss: 0.3841 - val_accuracy: 0.8711\n",
            "Epoch 371/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3433 - accuracy: 0.8701 - val_loss: 0.3803 - val_accuracy: 0.8713\n",
            "Epoch 372/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3387 - accuracy: 0.8684 - val_loss: 0.3804 - val_accuracy: 0.8711\n",
            "Epoch 373/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3319 - accuracy: 0.8724 - val_loss: 0.3703 - val_accuracy: 0.8713\n",
            "Epoch 374/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3455 - accuracy: 0.8658 - val_loss: 0.3847 - val_accuracy: 0.8711\n",
            "Epoch 375/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3370 - accuracy: 0.8726 - val_loss: 0.3871 - val_accuracy: 0.8711\n",
            "Epoch 376/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3255 - accuracy: 0.8753 - val_loss: 0.3949 - val_accuracy: 0.8713\n",
            "Epoch 377/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3296 - accuracy: 0.8731 - val_loss: 0.3768 - val_accuracy: 0.8713\n",
            "Epoch 378/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3310 - accuracy: 0.8738 - val_loss: 0.3815 - val_accuracy: 0.8713\n",
            "Epoch 379/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3284 - accuracy: 0.8764 - val_loss: 0.3774 - val_accuracy: 0.8713\n",
            "Epoch 380/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3287 - accuracy: 0.8751 - val_loss: 0.3883 - val_accuracy: 0.8713\n",
            "Epoch 381/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3283 - accuracy: 0.8683 - val_loss: 0.3937 - val_accuracy: 0.8711\n",
            "Epoch 382/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3285 - accuracy: 0.8733 - val_loss: 0.3848 - val_accuracy: 0.8715\n",
            "Epoch 383/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3295 - accuracy: 0.8738 - val_loss: 0.3922 - val_accuracy: 0.8711\n",
            "Epoch 384/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3352 - accuracy: 0.8714 - val_loss: 0.3735 - val_accuracy: 0.8713\n",
            "Epoch 385/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3792 - accuracy: 0.8676 - val_loss: 0.3729 - val_accuracy: 0.8713\n",
            "Epoch 386/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3591 - accuracy: 0.8750 - val_loss: 0.3709 - val_accuracy: 0.8713\n",
            "Epoch 387/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3536 - accuracy: 0.8732 - val_loss: 0.3681 - val_accuracy: 0.8713\n",
            "Epoch 388/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3445 - accuracy: 0.8753 - val_loss: 0.3727 - val_accuracy: 0.8713\n",
            "Epoch 389/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3442 - accuracy: 0.8732 - val_loss: 0.3707 - val_accuracy: 0.8713\n",
            "Epoch 390/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3380 - accuracy: 0.8729 - val_loss: 0.3725 - val_accuracy: 0.8713\n",
            "Epoch 391/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3389 - accuracy: 0.8755 - val_loss: 0.3751 - val_accuracy: 0.8713\n",
            "Epoch 392/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3402 - accuracy: 0.8754 - val_loss: 0.3745 - val_accuracy: 0.8713\n",
            "Epoch 393/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3405 - accuracy: 0.8708 - val_loss: 0.3736 - val_accuracy: 0.8713\n",
            "Epoch 394/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3429 - accuracy: 0.8703 - val_loss: 0.3768 - val_accuracy: 0.8713\n",
            "Epoch 395/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3296 - accuracy: 0.8731 - val_loss: 0.3747 - val_accuracy: 0.8713\n",
            "Epoch 396/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.8758 - val_loss: 0.3763 - val_accuracy: 0.8713\n",
            "Epoch 397/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3292 - accuracy: 0.8760 - val_loss: 0.3782 - val_accuracy: 0.8713\n",
            "Epoch 398/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3308 - accuracy: 0.8730 - val_loss: 0.3754 - val_accuracy: 0.8713\n",
            "Epoch 399/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3270 - accuracy: 0.8753 - val_loss: 0.3785 - val_accuracy: 0.8711\n",
            "Epoch 400/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3353 - accuracy: 0.8747 - val_loss: 0.3769 - val_accuracy: 0.8713\n",
            "Epoch 401/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3351 - accuracy: 0.8711 - val_loss: 0.3855 - val_accuracy: 0.8713\n",
            "Epoch 402/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3381 - accuracy: 0.8714 - val_loss: 0.3796 - val_accuracy: 0.8713\n",
            "Epoch 403/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3305 - accuracy: 0.8720 - val_loss: 0.3876 - val_accuracy: 0.8713\n",
            "Epoch 404/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3315 - accuracy: 0.8719 - val_loss: 0.3794 - val_accuracy: 0.8711\n",
            "Epoch 405/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3364 - accuracy: 0.8675 - val_loss: 0.3877 - val_accuracy: 0.8703\n",
            "Epoch 406/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3208 - accuracy: 0.8763 - val_loss: 0.3800 - val_accuracy: 0.8711\n",
            "Epoch 407/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3196 - accuracy: 0.8741 - val_loss: 0.3825 - val_accuracy: 0.8693\n",
            "Epoch 408/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3263 - accuracy: 0.8777 - val_loss: 0.3820 - val_accuracy: 0.8691\n",
            "Epoch 409/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3185 - accuracy: 0.8766 - val_loss: 0.3938 - val_accuracy: 0.8677\n",
            "Epoch 410/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3249 - accuracy: 0.8736 - val_loss: 0.3864 - val_accuracy: 0.8639\n",
            "Epoch 411/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3335 - accuracy: 0.8713 - val_loss: 0.3891 - val_accuracy: 0.8711\n",
            "Epoch 412/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3555 - accuracy: 0.8756 - val_loss: 0.3789 - val_accuracy: 0.8711\n",
            "Epoch 413/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3525 - accuracy: 0.8749 - val_loss: 0.3883 - val_accuracy: 0.8713\n",
            "Epoch 414/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3398 - accuracy: 0.8741 - val_loss: 0.3830 - val_accuracy: 0.8691\n",
            "Epoch 415/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3384 - accuracy: 0.8752 - val_loss: 0.3933 - val_accuracy: 0.8667\n",
            "Epoch 416/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3355 - accuracy: 0.8762 - val_loss: 0.3782 - val_accuracy: 0.8673\n",
            "Epoch 417/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3387 - accuracy: 0.8728 - val_loss: 0.3786 - val_accuracy: 0.8685\n",
            "Epoch 418/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3400 - accuracy: 0.8718 - val_loss: 0.3823 - val_accuracy: 0.8685\n",
            "Epoch 419/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3380 - accuracy: 0.8744 - val_loss: 0.3905 - val_accuracy: 0.8677\n",
            "Epoch 420/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3356 - accuracy: 0.8781 - val_loss: 0.3830 - val_accuracy: 0.8665\n",
            "Epoch 421/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3265 - accuracy: 0.8803 - val_loss: 0.3916 - val_accuracy: 0.8661\n",
            "Epoch 422/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3277 - accuracy: 0.8747 - val_loss: 0.3830 - val_accuracy: 0.8657\n",
            "Epoch 423/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3286 - accuracy: 0.8764 - val_loss: 0.3836 - val_accuracy: 0.8647\n",
            "Epoch 424/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3342 - accuracy: 0.8755 - val_loss: 0.3845 - val_accuracy: 0.8617\n",
            "Epoch 425/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3389 - accuracy: 0.8698 - val_loss: 0.3939 - val_accuracy: 0.8659\n",
            "Epoch 426/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3511 - accuracy: 0.8694 - val_loss: 0.3789 - val_accuracy: 0.8679\n",
            "Epoch 427/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3332 - accuracy: 0.8769 - val_loss: 0.3910 - val_accuracy: 0.8641\n",
            "Epoch 428/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3175 - accuracy: 0.8804 - val_loss: 0.3870 - val_accuracy: 0.8655\n",
            "Epoch 429/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3153 - accuracy: 0.8843 - val_loss: 0.3849 - val_accuracy: 0.8649\n",
            "Epoch 430/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3208 - accuracy: 0.8803 - val_loss: 0.3852 - val_accuracy: 0.8611\n",
            "Epoch 431/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3244 - accuracy: 0.8808 - val_loss: 0.3958 - val_accuracy: 0.8551\n",
            "Epoch 432/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3227 - accuracy: 0.8811 - val_loss: 0.3908 - val_accuracy: 0.8657\n",
            "Epoch 433/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3375 - accuracy: 0.8752 - val_loss: 0.3845 - val_accuracy: 0.8635\n",
            "Epoch 434/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3379 - accuracy: 0.8743 - val_loss: 0.3977 - val_accuracy: 0.8675\n",
            "Epoch 435/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3365 - accuracy: 0.8747 - val_loss: 0.3842 - val_accuracy: 0.8677\n",
            "Epoch 436/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3413 - accuracy: 0.8735 - val_loss: 0.3856 - val_accuracy: 0.8713\n",
            "Epoch 437/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3405 - accuracy: 0.8738 - val_loss: 0.3911 - val_accuracy: 0.8689\n",
            "Epoch 438/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3252 - accuracy: 0.8794 - val_loss: 0.3904 - val_accuracy: 0.8629\n",
            "Epoch 439/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3269 - accuracy: 0.8780 - val_loss: 0.3975 - val_accuracy: 0.8641\n",
            "Epoch 440/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3139 - accuracy: 0.8843 - val_loss: 0.3938 - val_accuracy: 0.8589\n",
            "Epoch 441/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3334 - accuracy: 0.8807 - val_loss: 0.3982 - val_accuracy: 0.8613\n",
            "Epoch 442/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3191 - accuracy: 0.8850 - val_loss: 0.3953 - val_accuracy: 0.8543\n",
            "Epoch 443/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3488 - accuracy: 0.8633 - val_loss: 0.4078 - val_accuracy: 0.8657\n",
            "Epoch 444/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3232 - accuracy: 0.8818 - val_loss: 0.3996 - val_accuracy: 0.8629\n",
            "Epoch 445/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3120 - accuracy: 0.8854 - val_loss: 0.3975 - val_accuracy: 0.8653\n",
            "Epoch 446/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3155 - accuracy: 0.8811 - val_loss: 0.3992 - val_accuracy: 0.8609\n",
            "Epoch 447/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3276 - accuracy: 0.8796 - val_loss: 0.4111 - val_accuracy: 0.8629\n",
            "Epoch 448/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3312 - accuracy: 0.8780 - val_loss: 0.4003 - val_accuracy: 0.8649\n",
            "Epoch 449/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3344 - accuracy: 0.8751 - val_loss: 0.4025 - val_accuracy: 0.8649\n",
            "Epoch 450/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3250 - accuracy: 0.8833 - val_loss: 0.4003 - val_accuracy: 0.8621\n",
            "Epoch 451/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3127 - accuracy: 0.8855 - val_loss: 0.4073 - val_accuracy: 0.8625\n",
            "Epoch 452/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3239 - accuracy: 0.8832 - val_loss: 0.3914 - val_accuracy: 0.8615\n",
            "Epoch 453/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3195 - accuracy: 0.8841 - val_loss: 0.3982 - val_accuracy: 0.8619\n",
            "Epoch 454/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3299 - accuracy: 0.8760 - val_loss: 0.3994 - val_accuracy: 0.8533\n",
            "Epoch 455/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3263 - accuracy: 0.8784 - val_loss: 0.4022 - val_accuracy: 0.8635\n",
            "Epoch 456/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3121 - accuracy: 0.8841 - val_loss: 0.4040 - val_accuracy: 0.8649\n",
            "Epoch 457/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3154 - accuracy: 0.8842 - val_loss: 0.4091 - val_accuracy: 0.8579\n",
            "Epoch 458/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3309 - accuracy: 0.8758 - val_loss: 0.4039 - val_accuracy: 0.8585\n",
            "Epoch 459/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3272 - accuracy: 0.8791 - val_loss: 0.4104 - val_accuracy: 0.8657\n",
            "Epoch 460/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3244 - accuracy: 0.8786 - val_loss: 0.4081 - val_accuracy: 0.8639\n",
            "Epoch 461/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3101 - accuracy: 0.8846 - val_loss: 0.4127 - val_accuracy: 0.8607\n",
            "Epoch 462/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3238 - accuracy: 0.8810 - val_loss: 0.4171 - val_accuracy: 0.8613\n",
            "Epoch 463/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3159 - accuracy: 0.8834 - val_loss: 0.4100 - val_accuracy: 0.8587\n",
            "Epoch 464/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3160 - accuracy: 0.8835 - val_loss: 0.4220 - val_accuracy: 0.8599\n",
            "Epoch 465/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3164 - accuracy: 0.8815 - val_loss: 0.4041 - val_accuracy: 0.8647\n",
            "Epoch 466/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3405 - accuracy: 0.8730 - val_loss: 0.3887 - val_accuracy: 0.8631\n",
            "Epoch 467/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3164 - accuracy: 0.8828 - val_loss: 0.3945 - val_accuracy: 0.8609\n",
            "Epoch 468/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3120 - accuracy: 0.8836 - val_loss: 0.4021 - val_accuracy: 0.8597\n",
            "Epoch 469/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3223 - accuracy: 0.8827 - val_loss: 0.4113 - val_accuracy: 0.8553\n",
            "Epoch 470/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3025 - accuracy: 0.8888 - val_loss: 0.4092 - val_accuracy: 0.8605\n",
            "Epoch 471/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3095 - accuracy: 0.8867 - val_loss: 0.4201 - val_accuracy: 0.8563\n",
            "Epoch 472/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3101 - accuracy: 0.8833 - val_loss: 0.4271 - val_accuracy: 0.8591\n",
            "Epoch 473/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3168 - accuracy: 0.8822 - val_loss: 0.4088 - val_accuracy: 0.8541\n",
            "Epoch 474/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3203 - accuracy: 0.8819 - val_loss: 0.4151 - val_accuracy: 0.8603\n",
            "Epoch 475/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3162 - accuracy: 0.8869 - val_loss: 0.4186 - val_accuracy: 0.8617\n",
            "Epoch 476/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3110 - accuracy: 0.8879 - val_loss: 0.4083 - val_accuracy: 0.8631\n",
            "Epoch 477/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3128 - accuracy: 0.8863 - val_loss: 0.4205 - val_accuracy: 0.8649\n",
            "Epoch 478/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3100 - accuracy: 0.8855 - val_loss: 0.4251 - val_accuracy: 0.8619\n",
            "Epoch 479/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3169 - accuracy: 0.8844 - val_loss: 0.4142 - val_accuracy: 0.8667\n",
            "Epoch 480/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3338 - accuracy: 0.8796 - val_loss: 0.3817 - val_accuracy: 0.8685\n",
            "Epoch 481/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3381 - accuracy: 0.8749 - val_loss: 0.3904 - val_accuracy: 0.8639\n",
            "Epoch 482/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3115 - accuracy: 0.8887 - val_loss: 0.4010 - val_accuracy: 0.8657\n",
            "Epoch 483/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3199 - accuracy: 0.8818 - val_loss: 0.4197 - val_accuracy: 0.8601\n",
            "Epoch 484/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3104 - accuracy: 0.8861 - val_loss: 0.4342 - val_accuracy: 0.8647\n",
            "Epoch 485/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3229 - accuracy: 0.8815 - val_loss: 0.4329 - val_accuracy: 0.8577\n",
            "Epoch 486/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3084 - accuracy: 0.8861 - val_loss: 0.4060 - val_accuracy: 0.8595\n",
            "Epoch 487/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3192 - accuracy: 0.8833 - val_loss: 0.4248 - val_accuracy: 0.8629\n",
            "Epoch 488/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3265 - accuracy: 0.8796 - val_loss: 0.3833 - val_accuracy: 0.8599\n",
            "Epoch 489/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3307 - accuracy: 0.8780 - val_loss: 0.3975 - val_accuracy: 0.8613\n",
            "Epoch 490/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3196 - accuracy: 0.8809 - val_loss: 0.4087 - val_accuracy: 0.8617\n",
            "Epoch 491/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3202 - accuracy: 0.8844 - val_loss: 0.4196 - val_accuracy: 0.8629\n",
            "Epoch 492/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3114 - accuracy: 0.8833 - val_loss: 0.4105 - val_accuracy: 0.8583\n",
            "Epoch 493/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3050 - accuracy: 0.8886 - val_loss: 0.4145 - val_accuracy: 0.8571\n",
            "Epoch 494/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3211 - accuracy: 0.8816 - val_loss: 0.4230 - val_accuracy: 0.8595\n",
            "Epoch 495/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3203 - accuracy: 0.8814 - val_loss: 0.4307 - val_accuracy: 0.8621\n",
            "Epoch 496/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3164 - accuracy: 0.8867 - val_loss: 0.4276 - val_accuracy: 0.8601\n",
            "Epoch 497/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3285 - accuracy: 0.8835 - val_loss: 0.4114 - val_accuracy: 0.8653\n",
            "Epoch 498/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3225 - accuracy: 0.8819 - val_loss: 0.4265 - val_accuracy: 0.8619\n",
            "Epoch 499/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3096 - accuracy: 0.8878 - val_loss: 0.4218 - val_accuracy: 0.8637\n",
            "Epoch 500/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3083 - accuracy: 0.8886 - val_loss: 0.4260 - val_accuracy: 0.8627\n",
            "Epoch 501/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3059 - accuracy: 0.8901 - val_loss: 0.4342 - val_accuracy: 0.8511\n",
            "Epoch 502/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3174 - accuracy: 0.8856 - val_loss: 0.4273 - val_accuracy: 0.8589\n",
            "Epoch 503/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3175 - accuracy: 0.8820 - val_loss: 0.4258 - val_accuracy: 0.8517\n",
            "Epoch 504/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3161 - accuracy: 0.8843 - val_loss: 0.4383 - val_accuracy: 0.8619\n",
            "Epoch 505/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8898 - val_loss: 0.4268 - val_accuracy: 0.8615\n",
            "Epoch 506/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3057 - accuracy: 0.8869 - val_loss: 0.4376 - val_accuracy: 0.8599\n",
            "Epoch 507/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2996 - accuracy: 0.8898 - val_loss: 0.4431 - val_accuracy: 0.8543\n",
            "Epoch 508/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3126 - accuracy: 0.8850 - val_loss: 0.4314 - val_accuracy: 0.8591\n",
            "Epoch 509/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2989 - accuracy: 0.8902 - val_loss: 0.4343 - val_accuracy: 0.8571\n",
            "Epoch 510/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3078 - accuracy: 0.8867 - val_loss: 0.4276 - val_accuracy: 0.8551\n",
            "Epoch 511/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2995 - accuracy: 0.8898 - val_loss: 0.4325 - val_accuracy: 0.8543\n",
            "Epoch 512/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3201 - accuracy: 0.8845 - val_loss: 0.4368 - val_accuracy: 0.8613\n",
            "Epoch 513/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8897 - val_loss: 0.4168 - val_accuracy: 0.8593\n",
            "Epoch 514/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3087 - accuracy: 0.8885 - val_loss: 0.4395 - val_accuracy: 0.8587\n",
            "Epoch 515/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2940 - accuracy: 0.8923 - val_loss: 0.4425 - val_accuracy: 0.8523\n",
            "Epoch 516/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3310 - accuracy: 0.8760 - val_loss: 0.4145 - val_accuracy: 0.8581\n",
            "Epoch 517/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3195 - accuracy: 0.8802 - val_loss: 0.4291 - val_accuracy: 0.8549\n",
            "Epoch 518/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3126 - accuracy: 0.8824 - val_loss: 0.4261 - val_accuracy: 0.8639\n",
            "Epoch 519/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2963 - accuracy: 0.8936 - val_loss: 0.4306 - val_accuracy: 0.8565\n",
            "Epoch 520/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2928 - accuracy: 0.8919 - val_loss: 0.4349 - val_accuracy: 0.8555\n",
            "Epoch 521/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2975 - accuracy: 0.8913 - val_loss: 0.4433 - val_accuracy: 0.8527\n",
            "Epoch 522/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3090 - accuracy: 0.8873 - val_loss: 0.4459 - val_accuracy: 0.8583\n",
            "Epoch 523/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2976 - accuracy: 0.8904 - val_loss: 0.4386 - val_accuracy: 0.8597\n",
            "Epoch 524/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3153 - accuracy: 0.8856 - val_loss: 0.4419 - val_accuracy: 0.8621\n",
            "Epoch 525/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3038 - accuracy: 0.8878 - val_loss: 0.4701 - val_accuracy: 0.8579\n",
            "Epoch 526/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2846 - accuracy: 0.8972 - val_loss: 0.4562 - val_accuracy: 0.8583\n",
            "Epoch 527/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3030 - accuracy: 0.8899 - val_loss: 0.4539 - val_accuracy: 0.8589\n",
            "Epoch 528/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2859 - accuracy: 0.8949 - val_loss: 0.4450 - val_accuracy: 0.8549\n",
            "Epoch 529/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2946 - accuracy: 0.8931 - val_loss: 0.4465 - val_accuracy: 0.8561\n",
            "Epoch 530/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2958 - accuracy: 0.8942 - val_loss: 0.4497 - val_accuracy: 0.8583\n",
            "Epoch 531/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2966 - accuracy: 0.8960 - val_loss: 0.4365 - val_accuracy: 0.8647\n",
            "Epoch 532/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2959 - accuracy: 0.8929 - val_loss: 0.4612 - val_accuracy: 0.8631\n",
            "Epoch 533/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2872 - accuracy: 0.8955 - val_loss: 0.4655 - val_accuracy: 0.8591\n",
            "Epoch 534/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2958 - accuracy: 0.8935 - val_loss: 0.4429 - val_accuracy: 0.8533\n",
            "Epoch 535/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2909 - accuracy: 0.8935 - val_loss: 0.4673 - val_accuracy: 0.8491\n",
            "Epoch 536/700\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.3016 - accuracy: 0.8881 - val_loss: 0.4569 - val_accuracy: 0.8607\n",
            "Epoch 537/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3140 - accuracy: 0.8889 - val_loss: 0.4547 - val_accuracy: 0.8605\n",
            "Epoch 538/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2928 - accuracy: 0.8944 - val_loss: 0.4563 - val_accuracy: 0.8499\n",
            "Epoch 539/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3777 - accuracy: 0.8595 - val_loss: 0.3773 - val_accuracy: 0.8709\n",
            "Epoch 540/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3612 - accuracy: 0.8711 - val_loss: 0.3981 - val_accuracy: 0.8695\n",
            "Epoch 541/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3365 - accuracy: 0.8741 - val_loss: 0.4023 - val_accuracy: 0.8631\n",
            "Epoch 542/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3214 - accuracy: 0.8827 - val_loss: 0.4200 - val_accuracy: 0.8653\n",
            "Epoch 543/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3205 - accuracy: 0.8846 - val_loss: 0.4188 - val_accuracy: 0.8625\n",
            "Epoch 544/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3199 - accuracy: 0.8847 - val_loss: 0.4302 - val_accuracy: 0.8593\n",
            "Epoch 545/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3130 - accuracy: 0.8857 - val_loss: 0.4189 - val_accuracy: 0.8603\n",
            "Epoch 546/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3150 - accuracy: 0.8851 - val_loss: 0.4312 - val_accuracy: 0.8547\n",
            "Epoch 547/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3045 - accuracy: 0.8913 - val_loss: 0.4328 - val_accuracy: 0.8569\n",
            "Epoch 548/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3128 - accuracy: 0.8870 - val_loss: 0.4348 - val_accuracy: 0.8617\n",
            "Epoch 549/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3250 - accuracy: 0.8814 - val_loss: 0.4213 - val_accuracy: 0.8545\n",
            "Epoch 550/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3152 - accuracy: 0.8863 - val_loss: 0.4314 - val_accuracy: 0.8563\n",
            "Epoch 551/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3105 - accuracy: 0.8849 - val_loss: 0.4536 - val_accuracy: 0.8441\n",
            "Epoch 552/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3305 - accuracy: 0.8749 - val_loss: 0.4411 - val_accuracy: 0.8595\n",
            "Epoch 553/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3279 - accuracy: 0.8819 - val_loss: 0.4170 - val_accuracy: 0.8593\n",
            "Epoch 554/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3024 - accuracy: 0.8928 - val_loss: 0.4347 - val_accuracy: 0.8549\n",
            "Epoch 555/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3181 - accuracy: 0.8897 - val_loss: 0.4342 - val_accuracy: 0.8589\n",
            "Epoch 556/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2946 - accuracy: 0.8947 - val_loss: 0.4221 - val_accuracy: 0.8579\n",
            "Epoch 557/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3166 - accuracy: 0.8845 - val_loss: 0.4225 - val_accuracy: 0.8605\n",
            "Epoch 558/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3127 - accuracy: 0.8866 - val_loss: 0.4501 - val_accuracy: 0.8579\n",
            "Epoch 559/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3319 - accuracy: 0.8780 - val_loss: 0.4172 - val_accuracy: 0.8605\n",
            "Epoch 560/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3154 - accuracy: 0.8838 - val_loss: 0.4465 - val_accuracy: 0.8501\n",
            "Epoch 561/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3065 - accuracy: 0.8907 - val_loss: 0.4279 - val_accuracy: 0.8553\n",
            "Epoch 562/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3055 - accuracy: 0.8896 - val_loss: 0.4516 - val_accuracy: 0.8547\n",
            "Epoch 563/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3084 - accuracy: 0.8869 - val_loss: 0.4433 - val_accuracy: 0.8559\n",
            "Epoch 564/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3128 - accuracy: 0.8911 - val_loss: 0.4447 - val_accuracy: 0.8515\n",
            "Epoch 565/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3233 - accuracy: 0.8796 - val_loss: 0.4521 - val_accuracy: 0.8555\n",
            "Epoch 566/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3044 - accuracy: 0.8894 - val_loss: 0.4427 - val_accuracy: 0.8521\n",
            "Epoch 567/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3068 - accuracy: 0.8887 - val_loss: 0.4483 - val_accuracy: 0.8605\n",
            "Epoch 568/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3011 - accuracy: 0.8907 - val_loss: 0.4528 - val_accuracy: 0.8547\n",
            "Epoch 569/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3026 - accuracy: 0.8898 - val_loss: 0.4430 - val_accuracy: 0.8573\n",
            "Epoch 570/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2966 - accuracy: 0.8890 - val_loss: 0.4587 - val_accuracy: 0.8557\n",
            "Epoch 571/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3078 - accuracy: 0.8875 - val_loss: 0.4618 - val_accuracy: 0.8579\n",
            "Epoch 572/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2983 - accuracy: 0.8939 - val_loss: 0.4666 - val_accuracy: 0.8429\n",
            "Epoch 573/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3495 - accuracy: 0.8733 - val_loss: 0.3955 - val_accuracy: 0.8651\n",
            "Epoch 574/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3314 - accuracy: 0.8783 - val_loss: 0.4269 - val_accuracy: 0.8583\n",
            "Epoch 575/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3198 - accuracy: 0.8824 - val_loss: 0.4365 - val_accuracy: 0.8621\n",
            "Epoch 576/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3027 - accuracy: 0.8938 - val_loss: 0.4461 - val_accuracy: 0.8555\n",
            "Epoch 577/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3091 - accuracy: 0.8870 - val_loss: 0.4432 - val_accuracy: 0.8495\n",
            "Epoch 578/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3017 - accuracy: 0.8907 - val_loss: 0.4403 - val_accuracy: 0.8593\n",
            "Epoch 579/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2997 - accuracy: 0.8884 - val_loss: 0.4669 - val_accuracy: 0.8501\n",
            "Epoch 580/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3394 - accuracy: 0.8833 - val_loss: 0.4144 - val_accuracy: 0.8553\n",
            "Epoch 581/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3146 - accuracy: 0.8841 - val_loss: 0.4286 - val_accuracy: 0.8593\n",
            "Epoch 582/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3035 - accuracy: 0.8875 - val_loss: 0.4623 - val_accuracy: 0.8585\n",
            "Epoch 583/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2996 - accuracy: 0.8927 - val_loss: 0.4514 - val_accuracy: 0.8557\n",
            "Epoch 584/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3072 - accuracy: 0.8904 - val_loss: 0.4479 - val_accuracy: 0.8581\n",
            "Epoch 585/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2903 - accuracy: 0.8938 - val_loss: 0.4516 - val_accuracy: 0.8637\n",
            "Epoch 586/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2870 - accuracy: 0.8949 - val_loss: 0.4758 - val_accuracy: 0.8585\n",
            "Epoch 587/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3352 - accuracy: 0.8764 - val_loss: 0.4069 - val_accuracy: 0.8633\n",
            "Epoch 588/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3189 - accuracy: 0.8842 - val_loss: 0.4272 - val_accuracy: 0.8599\n",
            "Epoch 589/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2997 - accuracy: 0.8913 - val_loss: 0.4517 - val_accuracy: 0.8581\n",
            "Epoch 590/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2969 - accuracy: 0.8919 - val_loss: 0.4664 - val_accuracy: 0.8605\n",
            "Epoch 591/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2993 - accuracy: 0.8875 - val_loss: 0.4547 - val_accuracy: 0.8613\n",
            "Epoch 592/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3048 - accuracy: 0.8913 - val_loss: 0.4441 - val_accuracy: 0.8547\n",
            "Epoch 593/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3056 - accuracy: 0.8890 - val_loss: 0.4482 - val_accuracy: 0.8559\n",
            "Epoch 594/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2972 - accuracy: 0.8914 - val_loss: 0.4439 - val_accuracy: 0.8593\n",
            "Epoch 595/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2890 - accuracy: 0.8923 - val_loss: 0.4789 - val_accuracy: 0.8573\n",
            "Epoch 596/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2885 - accuracy: 0.8956 - val_loss: 0.4578 - val_accuracy: 0.8521\n",
            "Epoch 597/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2788 - accuracy: 0.8983 - val_loss: 0.4983 - val_accuracy: 0.8477\n",
            "Epoch 598/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2871 - accuracy: 0.8961 - val_loss: 0.4484 - val_accuracy: 0.8637\n",
            "Epoch 599/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3029 - accuracy: 0.8887 - val_loss: 0.4807 - val_accuracy: 0.8533\n",
            "Epoch 600/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2881 - accuracy: 0.8919 - val_loss: 0.4815 - val_accuracy: 0.8545\n",
            "Epoch 601/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2897 - accuracy: 0.8962 - val_loss: 0.4858 - val_accuracy: 0.8573\n",
            "Epoch 602/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2742 - accuracy: 0.9033 - val_loss: 0.5120 - val_accuracy: 0.8545\n",
            "Epoch 603/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2909 - accuracy: 0.8932 - val_loss: 0.4871 - val_accuracy: 0.8507\n",
            "Epoch 604/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2842 - accuracy: 0.8968 - val_loss: 0.4770 - val_accuracy: 0.8549\n",
            "Epoch 605/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2837 - accuracy: 0.8951 - val_loss: 0.4823 - val_accuracy: 0.8563\n",
            "Epoch 606/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2990 - accuracy: 0.8872 - val_loss: 0.4875 - val_accuracy: 0.8525\n",
            "Epoch 607/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3209 - accuracy: 0.8800 - val_loss: 0.4616 - val_accuracy: 0.8551\n",
            "Epoch 608/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3034 - accuracy: 0.8866 - val_loss: 0.4837 - val_accuracy: 0.8533\n",
            "Epoch 609/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2831 - accuracy: 0.8968 - val_loss: 0.4848 - val_accuracy: 0.8553\n",
            "Epoch 610/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3015 - accuracy: 0.8880 - val_loss: 0.5120 - val_accuracy: 0.8479\n",
            "Epoch 611/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2965 - accuracy: 0.8908 - val_loss: 0.4827 - val_accuracy: 0.8559\n",
            "Epoch 612/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2807 - accuracy: 0.8962 - val_loss: 0.4789 - val_accuracy: 0.8605\n",
            "Epoch 613/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2844 - accuracy: 0.8979 - val_loss: 0.4747 - val_accuracy: 0.8477\n",
            "Epoch 614/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2890 - accuracy: 0.8921 - val_loss: 0.5016 - val_accuracy: 0.8569\n",
            "Epoch 615/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2824 - accuracy: 0.8990 - val_loss: 0.4752 - val_accuracy: 0.8475\n",
            "Epoch 616/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2894 - accuracy: 0.8945 - val_loss: 0.4737 - val_accuracy: 0.8581\n",
            "Epoch 617/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2993 - accuracy: 0.8920 - val_loss: 0.5017 - val_accuracy: 0.8495\n",
            "Epoch 618/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2849 - accuracy: 0.8992 - val_loss: 0.4851 - val_accuracy: 0.8467\n",
            "Epoch 619/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3066 - accuracy: 0.8871 - val_loss: 0.4824 - val_accuracy: 0.8545\n",
            "Epoch 620/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2991 - accuracy: 0.8918 - val_loss: 0.5029 - val_accuracy: 0.8561\n",
            "Epoch 621/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2777 - accuracy: 0.8980 - val_loss: 0.5124 - val_accuracy: 0.8495\n",
            "Epoch 622/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2790 - accuracy: 0.8964 - val_loss: 0.5006 - val_accuracy: 0.8561\n",
            "Epoch 623/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2787 - accuracy: 0.8990 - val_loss: 0.5256 - val_accuracy: 0.8477\n",
            "Epoch 624/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2787 - accuracy: 0.8964 - val_loss: 0.5099 - val_accuracy: 0.8589\n",
            "Epoch 625/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2770 - accuracy: 0.8989 - val_loss: 0.5329 - val_accuracy: 0.8469\n",
            "Epoch 626/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2799 - accuracy: 0.9006 - val_loss: 0.4902 - val_accuracy: 0.8579\n",
            "Epoch 627/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3432 - accuracy: 0.8837 - val_loss: 0.4219 - val_accuracy: 0.8641\n",
            "Epoch 628/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3138 - accuracy: 0.8832 - val_loss: 0.4821 - val_accuracy: 0.8577\n",
            "Epoch 629/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2919 - accuracy: 0.8937 - val_loss: 0.4825 - val_accuracy: 0.8559\n",
            "Epoch 630/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2824 - accuracy: 0.8963 - val_loss: 0.5023 - val_accuracy: 0.8503\n",
            "Epoch 631/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2742 - accuracy: 0.9004 - val_loss: 0.4786 - val_accuracy: 0.8573\n",
            "Epoch 632/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2735 - accuracy: 0.8984 - val_loss: 0.4970 - val_accuracy: 0.8473\n",
            "Epoch 633/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8868 - val_loss: 0.5077 - val_accuracy: 0.8571\n",
            "Epoch 634/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2787 - accuracy: 0.8977 - val_loss: 0.4944 - val_accuracy: 0.8581\n",
            "Epoch 635/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2749 - accuracy: 0.8982 - val_loss: 0.5214 - val_accuracy: 0.8577\n",
            "Epoch 636/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2786 - accuracy: 0.8940 - val_loss: 0.5311 - val_accuracy: 0.8483\n",
            "Epoch 637/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2828 - accuracy: 0.8972 - val_loss: 0.5308 - val_accuracy: 0.8445\n",
            "Epoch 638/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3318 - accuracy: 0.8857 - val_loss: 0.4692 - val_accuracy: 0.8573\n",
            "Epoch 639/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2740 - accuracy: 0.9006 - val_loss: 0.4946 - val_accuracy: 0.8543\n",
            "Epoch 640/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2809 - accuracy: 0.8982 - val_loss: 0.5234 - val_accuracy: 0.8533\n",
            "Epoch 641/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2678 - accuracy: 0.9017 - val_loss: 0.5077 - val_accuracy: 0.8539\n",
            "Epoch 642/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2627 - accuracy: 0.9064 - val_loss: 0.5275 - val_accuracy: 0.8555\n",
            "Epoch 643/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2775 - accuracy: 0.8998 - val_loss: 0.5258 - val_accuracy: 0.8597\n",
            "Epoch 644/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3094 - accuracy: 0.8900 - val_loss: 0.4611 - val_accuracy: 0.8529\n",
            "Epoch 645/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2792 - accuracy: 0.8988 - val_loss: 0.5059 - val_accuracy: 0.8531\n",
            "Epoch 646/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2691 - accuracy: 0.9005 - val_loss: 0.5172 - val_accuracy: 0.8469\n",
            "Epoch 647/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2781 - accuracy: 0.8986 - val_loss: 0.5089 - val_accuracy: 0.8531\n",
            "Epoch 648/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3024 - accuracy: 0.8898 - val_loss: 0.4974 - val_accuracy: 0.8547\n",
            "Epoch 649/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2800 - accuracy: 0.8974 - val_loss: 0.5236 - val_accuracy: 0.8483\n",
            "Epoch 650/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2705 - accuracy: 0.9012 - val_loss: 0.5301 - val_accuracy: 0.8523\n",
            "Epoch 651/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2644 - accuracy: 0.9031 - val_loss: 0.5369 - val_accuracy: 0.8507\n",
            "Epoch 652/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2677 - accuracy: 0.9037 - val_loss: 0.5217 - val_accuracy: 0.8505\n",
            "Epoch 653/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2606 - accuracy: 0.9047 - val_loss: 0.5429 - val_accuracy: 0.8489\n",
            "Epoch 654/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2769 - accuracy: 0.8975 - val_loss: 0.5362 - val_accuracy: 0.8539\n",
            "Epoch 655/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2654 - accuracy: 0.9019 - val_loss: 0.5178 - val_accuracy: 0.8503\n",
            "Epoch 656/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2677 - accuracy: 0.9037 - val_loss: 0.5363 - val_accuracy: 0.8451\n",
            "Epoch 657/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2726 - accuracy: 0.8989 - val_loss: 0.5251 - val_accuracy: 0.8495\n",
            "Epoch 658/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2979 - accuracy: 0.8931 - val_loss: 0.4823 - val_accuracy: 0.8473\n",
            "Epoch 659/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2792 - accuracy: 0.8989 - val_loss: 0.5427 - val_accuracy: 0.8487\n",
            "Epoch 660/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3474 - accuracy: 0.8846 - val_loss: 0.4294 - val_accuracy: 0.8511\n",
            "Epoch 661/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2879 - accuracy: 0.8988 - val_loss: 0.5081 - val_accuracy: 0.8495\n",
            "Epoch 662/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2563 - accuracy: 0.9086 - val_loss: 0.5035 - val_accuracy: 0.8479\n",
            "Epoch 663/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2720 - accuracy: 0.9017 - val_loss: 0.5205 - val_accuracy: 0.8479\n",
            "Epoch 664/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2676 - accuracy: 0.8997 - val_loss: 0.5770 - val_accuracy: 0.8525\n",
            "Epoch 665/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2707 - accuracy: 0.9048 - val_loss: 0.5484 - val_accuracy: 0.8425\n",
            "Epoch 666/700\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.3011 - accuracy: 0.8899 - val_loss: 0.5052 - val_accuracy: 0.8573\n",
            "Epoch 667/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2833 - accuracy: 0.8975 - val_loss: 0.5307 - val_accuracy: 0.8447\n",
            "Epoch 668/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2738 - accuracy: 0.9000 - val_loss: 0.5431 - val_accuracy: 0.8447\n",
            "Epoch 669/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2612 - accuracy: 0.9045 - val_loss: 0.5488 - val_accuracy: 0.8519\n",
            "Epoch 670/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2608 - accuracy: 0.9069 - val_loss: 0.5629 - val_accuracy: 0.8555\n",
            "Epoch 671/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2726 - accuracy: 0.9012 - val_loss: 0.5448 - val_accuracy: 0.8523\n",
            "Epoch 672/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2796 - accuracy: 0.8988 - val_loss: 0.5753 - val_accuracy: 0.8485\n",
            "Epoch 673/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2614 - accuracy: 0.9027 - val_loss: 0.5446 - val_accuracy: 0.8535\n",
            "Epoch 674/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2631 - accuracy: 0.9014 - val_loss: 0.5601 - val_accuracy: 0.8365\n",
            "Epoch 675/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2777 - accuracy: 0.8992 - val_loss: 0.5093 - val_accuracy: 0.8515\n",
            "Epoch 676/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2624 - accuracy: 0.9032 - val_loss: 0.5368 - val_accuracy: 0.8449\n",
            "Epoch 677/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2573 - accuracy: 0.9046 - val_loss: 0.5542 - val_accuracy: 0.8559\n",
            "Epoch 678/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2778 - accuracy: 0.8991 - val_loss: 0.5063 - val_accuracy: 0.8523\n",
            "Epoch 679/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2691 - accuracy: 0.9025 - val_loss: 0.5343 - val_accuracy: 0.8533\n",
            "Epoch 680/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2674 - accuracy: 0.9013 - val_loss: 0.5475 - val_accuracy: 0.8505\n",
            "Epoch 681/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3024 - accuracy: 0.8920 - val_loss: 0.4805 - val_accuracy: 0.8509\n",
            "Epoch 682/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2832 - accuracy: 0.8967 - val_loss: 0.4886 - val_accuracy: 0.8469\n",
            "Epoch 683/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2654 - accuracy: 0.9030 - val_loss: 0.5263 - val_accuracy: 0.8457\n",
            "Epoch 684/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2750 - accuracy: 0.8987 - val_loss: 0.5443 - val_accuracy: 0.8509\n",
            "Epoch 685/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2761 - accuracy: 0.9048 - val_loss: 0.5309 - val_accuracy: 0.8505\n",
            "Epoch 686/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2594 - accuracy: 0.9084 - val_loss: 0.5704 - val_accuracy: 0.8535\n",
            "Epoch 687/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2588 - accuracy: 0.9053 - val_loss: 0.5513 - val_accuracy: 0.8483\n",
            "Epoch 688/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3085 - accuracy: 0.8889 - val_loss: 0.4754 - val_accuracy: 0.8507\n",
            "Epoch 689/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3144 - accuracy: 0.8872 - val_loss: 0.4357 - val_accuracy: 0.8521\n",
            "Epoch 690/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.3127 - accuracy: 0.8828 - val_loss: 0.4820 - val_accuracy: 0.8543\n",
            "Epoch 691/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2946 - accuracy: 0.8934 - val_loss: 0.4922 - val_accuracy: 0.8531\n",
            "Epoch 692/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2800 - accuracy: 0.8957 - val_loss: 0.4921 - val_accuracy: 0.8507\n",
            "Epoch 693/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2851 - accuracy: 0.9009 - val_loss: 0.5031 - val_accuracy: 0.8507\n",
            "Epoch 694/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2678 - accuracy: 0.9029 - val_loss: 0.5026 - val_accuracy: 0.8521\n",
            "Epoch 695/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2788 - accuracy: 0.8975 - val_loss: 0.5343 - val_accuracy: 0.8527\n",
            "Epoch 696/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2634 - accuracy: 0.9052 - val_loss: 0.5327 - val_accuracy: 0.8473\n",
            "Epoch 697/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2698 - accuracy: 0.9028 - val_loss: 0.5418 - val_accuracy: 0.8449\n",
            "Epoch 698/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2571 - accuracy: 0.9071 - val_loss: 0.5697 - val_accuracy: 0.8489\n",
            "Epoch 699/700\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.2637 - accuracy: 0.9062 - val_loss: 0.5187 - val_accuracy: 0.8447\n",
            "Epoch 700/700\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2899 - accuracy: 0.8963 - val_loss: 0.5375 - val_accuracy: 0.8419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "65irl8C5vWyR",
        "outputId": "c111a8f0-ee0a-4149-bffe-2af63a695d88"
      },
      "source": [
        "### 4\n",
        "# Plot the loss and accuracy for training and validation sets\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hist.history['loss'], 'y', label='train loss')\n",
        "plt.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "plt.ylim(bottom=0)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hist.history['accuracy'], 'b', label='train accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], 'g', label='val accuracy')\n",
        "plt.ylim(bottom=0)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuray')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "# Compute and print final test loss and accuracy\n",
        "# model.evaluate evaluates the error of your model on \n",
        "# the inputs and labels you pass it. \n",
        "loss_and_acc = model.evaluate(x_test, y_test, batch_size=np.shape(x_test)[0])\n",
        "print('Final Test set Loss:',loss_and_acc[0])\n",
        "print('Final Test set Accuracy:',loss_and_acc[1])"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 185ms/step - loss: 0.5375 - accuracy: 0.8419\n",
            "Final Test set Loss: 0.5374835133552551\n",
            "Final Test set Accuracy: 0.8419051170349121\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq6ft_DX2DCP"
      },
      "source": [
        "TestingGuesses = np.zeros(len(y_test))\n",
        "for i in range(len(TestingGuesses)):\n",
        "  TestingGuesses[i] = model.predict(x_test[i,:,:].reshape(1,1,31))"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZHS-kQtJE1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46e23524-e98f-4cbe-eb94-c0b3cf8abe0d"
      },
      "source": [
        "withdrawn = y_test[y_test==0]\n",
        "completed = y_test[y_test==1]\n",
        "guess_withdrawn = TestingGuesses[(y_test==0).reshape(len(y_test))]\n",
        "guess_completed = TestingGuesses[(y_test==1).reshape(len(y_test))]\n",
        "\n",
        "print(guess_withdrawn.mean())\n",
        "print(guess_completed.mean())\n",
        "\n",
        "\n",
        "guess_completed[guess_completed > .5] = 1\n",
        "guess_completed[guess_completed < .5] = 0\n",
        "guess_withdrawn[guess_withdrawn > .5] = 1\n",
        "guess_withdrawn[guess_withdrawn < .5] = 0"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.802090496135134\n",
            "0.8762683586038615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqGiVG4AJ_BD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1798daaf-51b8-4aa1-85c9-54ff36f9269f"
      },
      "source": [
        "print('Actual:W, Predict: C',np.sum(np.abs(withdrawn-guess_withdrawn)))\n",
        "print('Actual:C, Predict: W',np.sum(np.abs(completed-guess_completed)))\n",
        "print('Actual:W, Predict: W',len(withdrawn) - np.sum(np.abs(withdrawn-guess_withdrawn)))\n",
        "print('Actual:C, Predict: C',len(completed) - np.sum(np.abs(completed-guess_completed)))"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual:W, Predict: C 586.0\n",
            "Actual:C, Predict: W 204.0\n",
            "Actual:W, Predict: W 57.0\n",
            "Actual:C, Predict: C 4150.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVWES3Avoez1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5d5ad91-055a-4f72-d5af-772294e738fb"
      },
      "source": [
        "guess_withdrawn = TestingGuesses[(y_test==0).reshape(len(y_test))]\n",
        "guess_completed = TestingGuesses[(y_test==1).reshape(len(y_test))]\n",
        "\n",
        "print(min(guess_withdrawn))\n",
        "print(min(guess_completed))\n",
        "print(max(guess_withdrawn))\n",
        "print(max(guess_completed))"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.003514927113428712\n",
            "0.0006710718735121191\n",
            "1.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhEJLBqarb-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74afa2f-4ce7-492f-dbd1-2fb598b2cfb1"
      },
      "source": [
        "print(len(TestingGuesses[(y_test==1).reshape(len(y_test))]))\n",
        "print(sum(TestingGuesses[(y_test==1).reshape(len(y_test))] > .99))\n",
        "\n",
        "print(len(TestingGuesses[(y_test==0).reshape(len(y_test))]))\n",
        "print(sum(TestingGuesses[(y_test==0).reshape(len(y_test))] > .99))"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4354\n",
            "1152\n",
            "643\n",
            "86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C_3rnMRV9b4",
        "outputId": "14dc533c-ba05-44eb-fff7-55d826ee4976"
      },
      "source": [
        "print(len(TestingGuesses[(y_test==1).reshape(len(y_test))]))\n",
        "print(sum(TestingGuesses[(y_test==1).reshape(len(y_test))] < .10))\n",
        "\n",
        "print(len(TestingGuesses[(y_test==0).reshape(len(y_test))]))\n",
        "print(sum(TestingGuesses[(y_test==0).reshape(len(y_test))] < .10))"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4354\n",
            "60\n",
            "643\n",
            "21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQan0jWzXgYo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}